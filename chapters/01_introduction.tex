\chapter{\statusgreen Introduction}
\label{chap:intro}

% ROUND 2 comments AW
% \todoAWinline{
% You say at the beginning that you’re going to talk about “persuasion” rather than “propaganda” or “framing”. And then you talk about “propaganda” a lot. Does that need tweaking?
% You give your 4 research hypotheses, but they’re all stated as straight facts, so I can’t work out what the actual hypothesis is. These want rephrasing so that it’s clear what is your hypothesis, and what are the facts which led to the hypothesis. “The first hypothesis is that… . This is based on Bloggs’ (1836) observation that…”
% }


% ROUND 1 comments
% \todoHAinline{Of course, at this stage, we’re not looking for perfection, so I focused more on the parts that are not at a ‘good enough’ level. This is mainly the RQs, and Hypotheses. I made suggestions for each RQ so consider those carefully. Wrt Hypotheses, I would expect them to map directly to your RQs, I think your 3rd H does, but the 1st and 2nd Hs seemed off the mark.
% The other weak part is Motivation. If you have time, try to spin the text around what problem you’re trying to solve or what new knowledge you’re trying to create. Current narrative is about what group of stakeholders you’re trying to benefit. This is generally not the point, and more so when the work does not involve any stakeholder groups; ie no user studies.}
% \todoAWinline{I think the basic content here is fine, but it's really verbose. There are points where what you're saying is confusing, and I suspect it's because you're not getting things sorted out in your own head before typing.
% I'd recommend attempting to reduce what you've written by a third, and that process might reveal how you could express your ideas more concisely.}

% Orientation: wider context

% situation
Thousands of news articles are published every day about the latest events around the world.
The use of specific language, the selection of details, and how the narrative is presented, are all different aspects that are unique to each news outlet and author.
These peculiarities, at the same time, can influence what the reader perceives about the events described.
% framing definition
This whole set of information, whether implicit or explicit, extends the raw facts of the events covered by news articles.
% and are shared as ground truth between multiple sources.
This additional layer, which varies across multiple news reports, comes under different names, such as \emph{framing}~\citep{gamson1989media,scheufele1999framing} or
%\emph{persuasion}, 
\emph{propaganda}, with slightly different definitions.
For conciseness, in this work we denote these techniques with the single term \emph{persuasion}.
These techniques are often conveyed with subjective statements, mixed with the objective description of the event narrated.
%, but there are also other factors.
%, but not only.
%it does not stop there.
% TODO reference: ``Various observers have noted how subtle framing subtly and unconsciously [framing] operates'' (Gamson and Modigliani, 1989, p. 7)
Even selecting which details or features to report greatly affects the message sent to the reader.

% introduce ideology/leaning
In this landscape of parallel news reports, there are multiple factors in play, such as political orientations and ideologies, that may influence the writing style of news outlets.
For example, persuasion may be used to push for political ideologies directly or indirectly.
% introduce topics
The persuasion used may also change with respect to the \emph{topic} of the news. Some topics are more polarising while others are more neutral.

% EXAMPLE NEEDED HERE

% % example
% For example, taking two sentences ``\textit{the black man was shot}'' vs ``\textit{the man was shot}'', they have a different framing because, although the man shot was black, it is a judgement of the reporter whether this detail needs to be emphasised or not, considering the ethnicity of the person who was shot to be important. %implying a form of racism with respect to a race-independent murder.

% Framing can have a big impact on the way readers perceive the content and relevance of the news~\citep{cohen2015press}. %(\textit{Agenda-setting}).

This thesis explores the relationships between persuasion, political orientation and topics.
These variables are studied independently in the existing literature, and this work aims at understanding the links between them.








% PhD Project done across \acrshort{kmi} and Computing\&Communications.

This chapter contains an introduction to the thesis.
Section~\ref{sec:intro_problem} contains the Problem Statement, Section~\ref{sec:intro_motivation} the Motivation, Section~\ref{sec:intro_rqs} contains all of our Research Questions. Then in Section~\ref{sec:intro_hyp} we present our hypotheses, and in Section~\ref{sec:intro_method} the general methodology used. We end the chapter with the main contributions in Section~\ref{sec:intro_contributions}, %the structure of the dissertation in Section~\ref{sec:intro_structure} 
and our publications in Section~\ref{sec:intro_publications}.


\section{\statusgreen Problem Statement}
\label{sec:intro_problem}


% At the intersection with misinformation, political issues, ...
% Study on propaganda

In this thesis, we analyse persuasion techniques, with a focus on propaganda, to understand how they relate to additional dimensions (topic, leaning, similarity).

To the best of our knowledge, there are hardly any computational studies that analyse the relationship between persuasion means, leaning, topics and similarity.
% This is not a problem on its own, but what is missing is an understanding of how these dimensions interact.
% Acquiring this missing knowledge, we could be able to 

What makes news articles about the same issue different?
Some studies focus on the information level, by considering which details are included (corroborated) or omitted~\citep{bountouridis2018explaining}.
This is done by comparing multiple parallel articles that cover the same story, and studying what overlaps and what is unique.

Then there is a second branch of research that instead investigates the use of linguistic techniques, such as persuasion, propaganda, sentiment and emotions. This second group tends to focus on single articles analysed on their own, in order to build models to detect such linguistic techniques over news articles~\citep{da2019fine}. %This set of features is considered as a layer of framing/propaganda on top of the facts described,\todoAW{Considered by whom? Don't use the passive!} and it needs to be properly recognised.

Then a third group of works sees the problems by considering only the political leaning. Here we find approaches to recognise political leaning from news articles~\citep{baly2020we}, to provide balanced news feeds to users (e.g. AllSides, Blue Feed - Red Feed), and to label the leanings of news sources (datasets e.g., Media Bias/Fact Check, AllSides).

The final group focuses on topic analysis. Researchers usually employ this method to break down many different types of results, belonging to different tasks and methodologies, to get more fine-grained insights~\citep{zhang2023strategic}.
% TODO: FIND SOME EXAMPLES OF TOPICS ANALYSIS FOR PROPAGANDA, NOT COMPUTATIONAL.
However, there is a lack of computational approaches or analyses that consider the topic as an additional variable to propaganda, leaning or similarity.


Between these multiple branches of research, we see potential links that are left unexplored.
For example, regarding the potential connection between propaganda and leaning, there is a lack in knowledge on \emph{what are the differences in persuasion/propaganda used by different political orientations?} or \emph{How can we automatically recognise political leaning from propaganda?}

% What is the relationship with the topics discussed?
Furthermore, if we consider the relationship between topics and propaganda, it would be useful to understand \emph{which topics tend to attract more propaganda} and \emph{which ones are targets for polarised propaganda}. Adding also the leaning, to \emph{identify topics where propaganda is more distinguishable between political leanings}.
This would give insights into how propaganda changes across topics and leanings, considering both the quantity and the specific terminology used.
%This would on one side give insights about how the quantity of propaganda changes across topics and leanings, and on the other side about how the terminology used changes across techniques, leanings topics for the specific techniques of techniques used and specific terminology used. 

% \subsection{\statusgreen Key concepts}

% Here we describe the most important concepts that are touched in this thesis. For a complete list, please refer to the Glossary.
% \todoAW{I'm not sure what you're trying to achieve with this list. It feels a bit as though you're just dropping some key terms in, without giving a sense of why they need defining.}
% \todoHA{I think it’s good to provide definitions but I agree that it’s best to drop this section to save time at least. You can put it back if examiners ask for it. I also agree with AW’s comments on each definition.}

% \leftskip=3em
% \parindent=-3em

% \textbf{Event}: \glsdesc*{event}\footnote{\url{https://dictionary.cambridge.org/dictionary/english/event}}.

% \textbf{Parallel News}: \glsdesc*{parallel-news}

% \textbf{Similarity / Variations}: The specific combination of \gls{corroborate}[d] and \gls{omit}[ted] details.\todoAW{Not a sentence.} Terms that change.\todoAW{Not a sentence.} Similarity metrics\todoAW{So is it the details or the metrics? Again, precision!} that score how similar/dissimilar articles are.\todoAW{Not a sentence.}

% \textbf{Persuasion}: \glsdesc*{persuasion}

% \textbf{Propaganda}: \glsdesc{propaganda}

% \textbf{Political Leaning}: \glsdesc{political-leaning}

% \textbf{Topic}: \glsdesc{topic}


% \leftskip=0em
% \parindent 1.5em

\section{\statusgreen Motivation}
\label{sec:intro_motivation}

% % Rationale: create a niche
% % TODO why spotting is useful: http://faculty.sites.uci.edu/polletta/files/2016/02/22A-Simple-Intervention-to-Reduce-Framing-Effects-in-Perceptions-of-Global-Climate-Change22.pdf

% % need of comparing multiple articles
% Spotting the occurrence of framing is therefore a very difficult task, even for humans~\citep{morstatter2018identifying}. Something that could help in this situation is looking at different sources and analysing how they present the same event with different framing.
% By seeing ``the other sides'' of the story, we, as readers, could create a more complete picture and spot the differences at the macro (the perspective of the overall article) and micro-level (specific linguistic cues)~\citep{gamson1989media}.
% The main problem with this technique is that it requires a lot of time,
% and many people only read news articles superficially% very lazy while consuming the news
% ~\citep{pennycook2019lazy}.
% % to read, compare, track, and differentiate all the small details \todo{any citation to support this statement?}.
% % tech limitations
% At the moment, we can see a gap in the tools available to provide this functionality automatically.
% Some technologies analyse parts of the problem, e.g. by grouping articles together by events (news aggregators), or anti-plagiarism tools that spot sentences occurring in multiple documents, or theoretical studies and conceptualisations analysing framing under different aspects.
% But to our knowledge, none of them is bringing together different stories to highlight the framing differences automatically.


% % Aim: purpose of research

% This PhD aims at creating a methodology to extract and characterise framing differences among news articles.
% This includes on one side revealing the choices done by the authors, and bring to the light the types of techniques they use to stand their point of view (e.g., selection and emphasis of details, addition of subjective content).
% And on the other side, to study the information flow between sources and see which relationships exist between them. %(e.g., reusing content).


% Who can find this thesis useful?
% The motivations of this thesis are multiple.

By analysing the relationship between propaganda, political leanings and topics, we aim to understand how strongly they are linked together.
Modelling these factors together could be beneficial in improving the results of tasks that are considered in isolation.
% \todoHA{And what is the motivation behind your need to understand this relationship? What would this lead to, potentially?}
There is a wide literature, both theoretical and practical, about each of these factors.
On the qualitative research level, there are some works that explain and motivate this relationship by analysing a specific event or timeframe~\citep{pierri2023propaganda,golovchenko2020cross,blumberg1986comparative}.
However, on the computational side, we find a lack of approaches that consider these factors together.

A computational approach, which considers together document similarity, propaganda, leaning and topics, would contribute to knowledge in several ways:
% \todoHA{This is ok, but a better narrative would be to focus on where you are advancing knowledge, especially since you did not do any user studies that involved these stakeholders.. if you have time then change the narrative. }

% \todo{Motivation: focus more on advancing knowledge, take the points below and rewrite them to put focus on advancing knowledge}

% \begin{enumerate}
%     \item Computational Researchers:
\begin{enumerate}
    \item Quantify the relationship between political leaning and propaganda.
          %The literature assumes %\todoAW{Very vague and sweeping. How would you justify this? (Or refute it?)}
          We find examples in the literature~\citep{schudson2002news} that explain how the political ideology of news writers/editors conditions writing news articles, considering economic reasons, unconscious assumptions and reporter-sources relations that are linked to political leanings. Therefore, these factors result in news articles that contain more or less subtle persuasion techniques for the reader (one of which is propaganda). By analysing and quantifying these relationships, we can understand their importance.
          % contribution 1: compute weights of these relationships, understand better the relationships
    \item By using together these variables, we can try to improve some automated approaches that currently rely on just one input feature, such as political leaning classification
          % \todoHA{so this is the type of value added that I was looking for. If you reach a better understanding of X, then you can improve Y. This could go earlier in this section.}
          using propaganda and topic features. By exploiting the relationship between these features, we can help \acrfull{ml} models to have higher values for the target metrics. % contribution 2: improve F1 using mix of feature
    \item With an analysis that considers multiple variables, we may identify problems and inconsistencies that can only be discovered with combined analyses (e.g., data imbalance). This is a valuable point when using \acrshort{ml}-based approaches, as improving the quality of the data is a key element. % contribution 3: We highlight the problem of imbalanced dataset for propaganda detection
\end{enumerate}
% \todoHA{Fits better in a discussion section at the end of the thesis}
%     \item Users reading the news:
%     \begin{enumerate}
%         \item link and show similarities to other documents on how the same topic is covered.\todoAW{Not a sentence} Especially articles from other political leanings which may have a different angle.\todoAW{Not a sentence}
%         \item support with a tool to highlight propaganda, to be conscious of the techniques used in the articles at the word level. It is crucial for this analysis to be as accurate as possible, and that is why we aim to find insights which may help create or extend datasets\todoAW{Isn't the aim to actually do the highlighting? Do you do anything on how to extend datasets?} (e.g., in the case of unbalanced datasets).
%         \item understand better how propaganda distributes across leanings and topics, to be able to recognise more manipulation and be less manipulable.\todoAW{How is this different from the previous point?}
%     \end{enumerate}
% \end{enumerate}


% Motivation/Orientation: multiple narrations of the same events. Driven by multiple factors (selection criteria, point of view of author/publisher, relevance, agenda-setting, …)
% This is linked with Persuasion, but more specifically propaganda. Communication with the goal to persuade. Subtle or more explicit.
% What distinguishes one piece of news from the others about the same event? 

% Political ideology → writer/editor → news (facts + propaganda(opinion)) → persuasion of reader

% Rationale (niche): computational propaganda detection is at an early stage in the research community. Current detection is based on unbalanced datasets that particularly target right-leaning news.

% Aims/Goals of this thesis: 
% understand how propaganda varies across the political spectrum
% Computational perspective: is propaganda detection ready to work in news independently from the political orientation/leaning of the source?




\section{\statusgreen Research Questions}
\label{sec:intro_rqs}

Given this aim, we build a research path that gradually adds the different variables.

\begin{enumerate}
    \item We start from the first factor of similarity (and difference) between news articles, which is the motivation for our work in the first place. Being able to analyse the similarities and differences enables us to get a grasp on what effectively changes between related articles. Therefore, our first \acrfull{rq} is:\\
          \emph{RQ1: To what extent do news articles about the same events differ?}
    \item Then, we move our focus to the computational detection of persuasion techniques. How they can be detected, and what is the relationship to our first \acrshort{rq}1. This prepares us for the second research question: \\
          \emph{\acrshort{rq}2: To what extent can we automatically detect the persuasion techniques used in news articles?}
    \item Afterwards, we introduce the variable of political leaning, to understand how it relates to persuasion. This leads us to the third research question:\\
          \emph{\acrshort{rq}3: To what extent could the use of persuasion techniques help identify the political leaning of a news article?}
    \item Finally, we introduce the topic as the last variable, to break down the results found in the previous investigation. This is our last research question:\\
          \emph{\acrshort{rq}4: How does the use of propaganda differ across topics, and to what extent could this help determine the political leaning of articles?}
\end{enumerate}

We dedicate an experimental chapter to each of the \acrlong{rq}s: from Chapter~\ref{chap:common_ground_search} to Chapter~\ref{chap:topics}.
% Each of them is split into sub-questions, that we list and describe here to present all of them together.
Each one of them contains several sub-questions that we list here for comprehensiveness.


\subsubsection*{RQ1: To what extent do news articles about the same events differ?}

% We are interested in how can we analyse and compare multiple sources to identify unique perspectives and overlapping information, detect omissions and corroborations, and select effective similarity metrics.\todoAW{I don't think this text adds anything; you've already introduced the RQ, and I think the subquestions by themselves do a clearer job of giving the context.}
The sub-questions are the following:
\begin{enumerate}[label={\textbf{RQ1.\arabic*:}},leftmargin=2cm]
    \item How are new events reported differently by multiple sources?
    \item How could we identify what is unique for each report and what is common?
    \item To what extent can we automatically detect omission and corroboration across multiple articles?
    \item Which similarity metrics are best for detecting omission and corroboration?
\end{enumerate}

These questions are targeted in Chapter~\ref{chap:common_ground_search}.

\subsubsection*{RQ2: To what extent can we automatically detect the persuasion techniques used in news articles?}

With this second \acrlong{rq} we take into consideration the persuasion techniques. We have the following sub-questions:

\begin{enumerate}[label={\textbf{RQ2.\arabic*:}},leftmargin=2cm]
    \item To what extent could we automatically detect the persuasion techniques used by writers?
    \item Which persuasion techniques are detected more frequently than others?
    \item How do similar news articles differ in their use of persuasion techniques?
    \item To what extent could persuasion techniques be used to identify related news articles?
\end{enumerate}

These are answered in Chapter~\ref{chap:linguistic_persuasion}.

\subsubsection*{RQ3: To what extent could the use of persuasion techniques help identify the political leaning of a news article?}

We introduce with this question the variable of political leaning, to do a comparative analysis of propaganda with respect to it. The sub-questions are:

\begin{enumerate}[label={\textbf{RQ3.\arabic*:}},leftmargin=2cm]
    \item How does persuasion vary across the political spectrum?
    \item To what extent can we predict the political leaning of a news article by observing the propaganda it uses?
    \item How balanced are the current propaganda detection methods with regard to political leaning?
\end{enumerate}

These are analysed in Chapter~\ref{chap:political_sides}.

\subsubsection*{RQ4: How does the use of propaganda differ across topics, and to what extent could this help determine the political leaning of articles?}

This last question introduces the topics, and is split into three sub-questions:

\begin{enumerate}[label={\textbf{RQ4.\arabic*:}},leftmargin=2cm]
    \item How does detected propaganda differ across polarising versus neutral topics?
    \item How does detected propaganda differ across \emph{political leaning} in polarising and neutral topics?
    \item What are the effects of combining the propaganda features with the topic features, to recognise the leaning of a news article?
\end{enumerate}

These are answered in Chapter~\ref{chap:topics}.


% What is the relationship between propaganda and political leaning?
% Diffusion
% Does propaganda exist all across political leaning?
% Do existing propaganda datasets represent each leaning well?
% (Why is there this discrepancy between i) and ii)?)
% Term usage
% What terms are used in propaganda?
% Do different leanings use similar propaganda terms?
% Populism
% Is propaganda correlated to populism in literature?
% Does the correlation show up in the data?
% Topics (?)
% How is propaganda spread across topics (overall)?
% Do different leanings use propaganda with different topics?
% Targets of propaganda (?)
% Who are the targets of propaganda (overall)?
% Do different leanings have different targets of propaganda?
% Prediction
% Is it possible to predict the political leaning of an article from its propaganda features?
% By removing propaganda terms from articles? 



\section{\statusgreen Research Hypotheses}
\label{sec:intro_hyp}

This thesis is based on several hypotheses inspired by the literature analysis.
% Most of them come from the literature, mixed with common knowledge.

% layers of info and choice of terms
\emph{HYP1:} The first hypothesis is that news articles are created with different layers of information: (i) the facts being reported, and (ii) the (choice of) language used to report those facts.
% \todoAW{Hard to read. Use enumerate. Don't run enumerations into the main text!}
%\todoAW{Would it be clearer to talk about i/ the facts being reported, and ii/ the (choice of) language used to report those facts?}
These layers are not separate and are very intertwined. At the word level, we may have words that are strictly topical words or are strictly persuasive words. However, we may also have words that represent both layers, with specific terms chosen from a multitude of synonyms to push for a certain idea.
This hypothesis has grounds in the works of~\citet{jenkins2013thin,vanderwicken1995news,jang2023proximate,bountouridis2018explaining}.
With our \acrshort{rq}1, we aim to understand what changes between multiple articles about the same event. In this scenario, we have the layer of facts that is shared across articles, and the layer of choices that changes. Therefore, if we analyse what changes between articles, we end up with the second layer, and we can verify or refute this hypothesis.

% corroboration and choice of details
% \emph{HYP2:} News articles are written by choosing which details to include and which ones to skip, and this may be done on purpose to influence the reader. This assumes that there are multiple details to choose from, and the news outlets (writer/editor) need to make a selection for fitting in the desired length or more directly supporting a certain position. And everywhere manual selection is done, there is a possible point of bias. This hypothesis is described in~\citet{bountouridis2018explaining} while trying to computationally detect corroborations and omissions.
\emph{HYP2:} The second hypothesis is that some choices are made with the aim of influencing the reader. Language allows great expressiveness and language choices allow very different messages to be conveyed. This is based on the work of~\citet{gass2018persuasion} that observes that the news is not exempt from conveying persuasive messages even when trying to transmit a neutral point of view.
Our \acrshort{rq}2 aims at understanding how well we can detect persuasion techniques. By answering this question, we can recognise attempts to influence and persuade the reader with specific techniques.

% propaganda and leaning
\emph{HYP3:} The third hypothesis is that propaganda language used by different political leanings is distinguishable. This would mean that Left and Right leaning have specific techniques or wordings that they use for example to target political opponents. The hypothesis is based on theoretical works from the literature that compare specific cases~\citep{blumberg1986comparative}, but we want to see if we can detect computationally such differences in techniques and wordings.
\acrshort{rq}3 goes in this direction, finding the differences between propaganda used by Left and Right.

% topic
\emph{HYP4:} Our last hypothesis is that propaganda is more strongly present in articles about certain topics than others. This could happen on topics that are more polarising and public debate is much more accentuated on them (e.g., elections, immigration, environment). On the other side, there may be very little propaganda or none on certain topics (e.g., art, weather).
With \acrshort{rq}4 we aim to understand how propaganda varies across topics and leanings.
% \todoAWinline{
% You haven't really phrased this (or any of the previous three) as a hypothesis. Particularly when you get onto "These topics are more polarising and public debate is more accentuated...", I don't know whether that is part of your hypothesis, or whether it's a fact on which you've built the hypothesis. Similarly, you say "On the other side, there is very little propaganda or none on certain topics": is that a hypothesis or a fact? Need to rephrase all the research hypotheses so that it's clear what is a hypothesis, and what is a supporting fact.
% }

% % unbalance
% Current propaganda detection recognises better right-leaning propaganda

% TODO: add others?

% We have more specific hypotheses in the following experimental chapters.

\section{\statusgreen Research Methodology}
\label{sec:intro_method}

On a broad level, our work is about computationally distinguishing propaganda across leanings and topics. Therefore, we use a methodology that is based on quantitative comparative analyses of propaganda and on comparing results with different feature sets.
%\todoAW{Is it? This makes your work sound like an aspect of media studies. Is it more that your methodology is about computationally distinguishable features of different types of propaganda?} across multiple dimensions (leaning, topic).

As we described in the previous sections, methodologically we take one concept at a time, and we add it to our analysis. For this reason, Chapter~\ref{chap:common_ground_search} treats similarity and overlap between multiple articles, then Chapter~\ref{chap:linguistic_persuasion} moves to linguistic techniques of persuasion. The chapters afterwards add Leaning (Chapter~\ref{chap:political_sides}) and Topics (Chapter~\ref{chap:topics}) to the comparative analysis. In this way, we start with simpler conditions without many variables in play. We gradually join with additional variables, as we need to break down the results further.
% and find correlations between the factors considered.


If we go into more detail about the single experiments done in the thesis, we use several methodologies across the chapters:
\begin{itemize}
    \item classifier-based: for a big part of our experiments, we use a methodology that is usually employed with classifiers. This is based on the computation of a metric (macro F1 in this case) of how well the classifier is able to predict the correct label for the inputs (in this case news articles). We use this setup with a classifier to understand the impact of multiple input variables (text of the articles, propaganda features, topic labels) on predicting the correct political leaning of the articles (compared with ground truth labels).
          % \todoAW{I'd put a nod here to the dataset you've used, and a forward pointer to the relevant section.}
          In addition, this setup allows performing a \emph{confusion analysis}, to understand the labels that were predicted incorrectly. Depending on the model used, we can also perform a \emph{feature importance} analysis to evaluate the strength of the features to make the prediction, to understand what the model learns. This methodology is performed together with a significance test, which establishes the probability of the observed improvement happening by chance.
    \item comparative analysis: in Chapters~\ref{chap:political_sides} and \ref{chap:topics} we use quantitative comparative analysis
          % \todoAW{What's that? Give a citation.}
          to compare the distribution of one observed variable across multiple controlled variables. This methodology relies on aggregated metrics (such as average, median and standard variation) on a specific variable (e.g. quantity of a propaganda technique) to compare groups of articles and observe differences. We extract patterns of association between variables and observations from statistics across the groups.
\end{itemize}


\section{\statusgreen Contributions}
\label{sec:intro_contributions}

The major contributions of this work are the following:
\begin{enumerate}
    \item Improving F1 of the political leaning classifier using a mix of features. More specifically:
          \begin{enumerate}
              \item Chapter~\ref{chap:political_sides}  shows that if we add propaganda features on a BERT-based~\citep{devlin2018bert} classifier that predicts political leaning, we produce slightly better results that are significant according to McNemar tests. In these cases, the propaganda features help to correct some imbalances of the baseline classifier. However, the number of samples affected is quite small.
              \item Chapter~\ref{chap:topics} adds the topic and uses it as a feature for the classifier. The result is an increase in the prediction metrics, small but significant.
          \end{enumerate}
    \item Computing weights and better understanding the relationships between the multiple dimensions of similarities, propaganda, leaning and topics. This is achieved with:
          \begin{enumerate}
              \item Chapter~\ref{chap:linguistic_persuasion} contains an analysis of the relationship between persuasion and the word variations that different news sources produce when reporting events.
              \item Chapter~\ref{chap:political_sides} investigates the correlation between propaganda and political leaning, demonstrated with an improvement of the F1 metric on the political leaning classification task. If they were not correlated, adding propaganda as an input feature would have no effect.
              \item Chapter~\ref{chap:topics} finds that the topic of the articles is correlated with propaganda: some topics have very high levels of propaganda, while other ones are less polarizing and contain less of it. Furthermore, we find that the terms of propaganda are very different across political leanings for specific topics. %This not only means that the correlation between topics, leanings and propaganda is high, but it also means that
                    %Certain topics have more propaganda on a specific leaning. This happens with topics that are more important from the considered point of view, or where the considered leaning is currently against the status quo.
                    % \item Distribution of propaganda techniques is very similar across leanings for most of the topics (relative ratio of the quantity of techniques between themselves). Combined with the previous finding, it means that the quantities of the techniques scale proportionally across leanings in most of the topics.
                    % \item Terms of propaganda can be quite different across political leaning in certain topics. For some of these topics, they already have an imbalance of total quantity (e.g. Left has more propaganda than Right), for some others, the quantity is very similar, but they differ in the terms used.
                    % \item For a set of topics, it is easier to classify correctly the political leaning than in others. The easiest topics are the ones that are more polarising.
                    % \item Adding propaganda features to the baseline model has a positive impact on prediction metrics on major topics, while for some topics instead, it has negative impacts.

          \end{enumerate}
    \item Highlighting the problem of imbalanced dataset for propaganda detection.
          % \todoAW{Given the extensive coverage of bias in LLMs over the last few months, to what extent is this a contribution? Or how can you phrase it so it's obviously an original contribution?} 
          We identify that the current datasets for propaganda detection are under-representing left-leaning propaganda, which is less common but still needs to be considered.
          This emerges from the analysis in different chapters:
          \begin{enumerate}
              \item Chapter~\ref{chap:linguistic_persuasion} results in a deeper understanding of the limitations of the current status of automated propaganda detection, and the repercussions it can have when we use these methods in other tasks (e.g. overlap across news articles).
                    % Computational detection of persuasion means is quite a recent research area, and with time and more resources (datasets and models) it could clearly improve
              \item Chapter~\ref{chap:political_sides} analyses and finds a big imbalance of propaganda detection datasets considering political leaning. Almost only right-leaning articles are used in the current literature.
                    % First of all, they show how current propaganda detection is able to work with articles coming from very different political orientations. We think that the results here found are demonstrating quite good abilities to generalise from the relatively small datasets used for training propaganda.
                    % And if we consider that a big proportion of the news used in our experiments comes from a different political leaning, we think that these are very promising results.
                    % We were able to extract, analyse and link to our external knowledge of the events and ideologies. This is a very positive outcome.
              \item Chapter~\ref{chap:topics} expands on this imbalance and finds topics that contain more or less propaganda generally or in a specific political leaning.
          \end{enumerate}


          % \item Chapter 3: As already denoted by the work of~\citet{bountouridis2018explaining}, we confirm a positive correlation between corroboration and credibility of news outlets and a negative correlation between omission and credibility. We went one step further, by being able to automatically find the specific words that change between multiple news articles, and identify the degree of uniqueness of them. We think that this is beneficial for many downstream tasks, such as showing to the user during annotation tasks or even when consuming news online. 
          % \item Observing similarities between multiple documents is made very difficult by linguistic variations. We experimented with models (e.g. \acrshort{use}) that are more resistant to words that carry similar meanings and are a better fit for doing this type of analysis.


          % \item Chapter 4: chapter highlighted how, by integrating the automated detection of persuasion in news articles, we have on one side a clearer idea of the relationship between persuasion and the variations that different news sources produce when reporting events.
          % \item On the other side, we have also a deeper understanding of the limitations of the current status of this automated detection, and the repercussions it can have when we use these methods in other tasks.
          % Computational detection of persuasion means is quite a recent research area, and with time and more resources (datasets and models) it could clearly improve

          % \item Chapter 5: % - positive: generalisation quite good considering datasets and results obtained
          % First of all, they show how current propaganda detection is able to work with articles coming from very different political orientations. We think that the results here found are demonstrating quite good abilities to generalise from the relatively small datasets used for training propaganda.
          % And if we consider that a big proportion of the news used in our experiments comes from a different political leaning, we think that these are very promising results.
          % We were able to extract, analyse and link to our external knowledge of the events and ideologies. This is a very positive outcome.

          % - finding TOPICS where difference is more accentuated
          % At the same time, this chapter has also helped us to find a direction for more investigation. The results found here represent the whole dataset. We would like to know if we can spot more in details the differences of propaganda when we consider specific topics separately. Propaganda may differ between political leanings more when we select certain topics, and we would like to know both which topics and also the outcomes of such a detailed analysis. And for conducing this experimentation, we need to consider the \emph{topics} of the articles as an additional element.

          % \item Chapter 6: \item We need fine-grained topic to be able to see differences. The coarse topics show similar propaganda across topics and leanings. The more we use fine-grained topics, the more differences we are able to see. But at the same time, we lose support (fewer articles specific to the topics, and the filtering becomes too narrow). We need a tradeoff between granularity (high to see good differences) and support (significance of results).
          % \item Certain topics have more propaganda on a specific leaning. This happens with topics that are more important from the considered point of view, or where the considered leaning is currently against the status quo.
          % \item Distribution of propaganda techniques is very similar across leanings for most of the topics (relative ratio of the quantity of techniques between themselves). Combined with the previous finding, it means that the quantities of the techniques scale proportionally across leanings in most of the topics.
          % \item Terms of propaganda can be quite different across political leaning in certain topics. For some of these topics, they already have an imbalance of total quantity (e.g. Left has more propaganda than Right), for some others, the quantity is very similar, but they differ in the terms used.
          % \item For a set of topics, it is easier to classify correctly the political leaning than in others. The easiest topics are the ones that are more polarising.
          % \item Adding propaganda features to the baseline model has a positive impact on prediction metrics on major topics, while for some topics instead, it has negative impacts.
          % \item Encoding the topic information and using it as a feature, helps increase the prediction metrics of a leaning classifier. The improvements are small but significant.


          % \item Topics where current automated propaganda detection is more problematic (TODO) 
          % \item Link between propaganda and political leaning is weak (not enough to identify leaning by just looking at the propaganda techniques) → against HYP1
          % \item Imbalance is / is-not a problem for propaganda detection
\end{enumerate}





% \section{\statusred Structure of the dissertation}
% \label{sec:intro_structure}

% ALREADY DONE WITH RQ AND METHODOLOGY, USELESS TO REPEAT

% Chapter~\ref{chap:literature} literature.

% Then chapters 3-6 experimental:

% Chapter 3: Common Ground Search,
% Chapter 4: Linguistic Proxies of Persuasion,
% Chapter 5: Perspectives and Political Sides,
% Chapter 6: Topics.

% Chapter~\ref{chap:discussion}: discussions and conclusions.

\section{\statusgreen Publications}
\label{sec:intro_publications}

During the timeframe of this PhD, multiple publications have been accepted at workshops and conferences. Some of them are strictly related to the topic of this thesis~\citep{mensio2020towards,mensio2020one}, while others are not directly linked to the topics here presented but still in the same broad research area of news analysis, news media and the response of the public to manipulation and misleading information (under the measure of Credibility).

% \subsection{Related to this thesis}

% Towards a Cross-article Narrative Comparison of News
% M Mensio, H Alani, A Willis
% Proceedings of the Text2Story’20 Workshop

% Mensio M., Willis A., Alani H. (April 2020) Towards a Cross-article Narrative Comparison of News. In Third International Workshop on Narrative Extraction from Texts held in conjunction with the 42nd European Conference on Information Retrieval (Text2Story2020 @ ECIR2020) [Full text (ORO)] [Full text (CEUR)] [Presentation slides]

% \fullcite{mensio2020towards}
\begin{itemize}
    \item \bibentry{mensio2020towards}
    \item \bibentry{mensio2020one}
    \item \bibentry{mensio2019news}
    \item \bibentry{mensio2019misinfome}
    \item \bibentry{mensio2020mitigating}
    \item \bibentry{mensio2023misinfome}
    \item \bibentry{burel2020co}
    \item \bibentry{piccolo2021agents}
    \item \bibentry{denaux2021weaving}
    \item \bibentry{lobo2022estimating}
          % \item \bibentry{mensio2023misinfokg}
\end{itemize}





% We present an idea for a system to perform cross-article narrative comparison.


% Mensio M., Alani H., Willis A. (June 2020) One Event, Different Stories. In Postgraduate Research Poster Competition 2020, The Open University [Multimedia entry (ORO)] [Poster (ORO)]



% \subsection{Other publications during the timeframe}

% Mensio M., Alani H. (October 2019) News Source Credibility in the Eyes of Different Assessors. In Conference for Truth and Trust Online (TTO 2019), London, UK [Full text (ORO)] [Full text (Conference)] [Slides]

% Mensio M., Alani H. (October 2019) MisinfoMe: Who’s Interacting with Misinformation? In (ISWC 2019) Posters and Demos [Poster] [Full text (ORO)] [Full text (CEUR)]


% Mensio M., Bastianelli E., Tiddi I., Rizzo G. (March 2020) Mitigating Bias in Deep Nets with Knowledge Bases: the Case of Natural Language Understanding for Robots. In AAAI 2020 Spring Symposium on Combining Machine Learning with Knowledge Engineering [Full text (CEUR)]

% Mensio M., Willis A., Alani H. (April 2020) Towards a Cross-article Narrative Comparison of News. In Third International Workshop on Narrative Extraction from Texts held in conjunction with the 42nd European Conference on Information Retrieval (Text2Story2020 @ ECIR2020) [Full text (ORO)] [Full text (CEUR)] [Presentation slides]

% Mensio M., Alani H., Willis A. (June 2020) One Event, Different Stories. In Postgraduate Research Poster Competition 2020, The Open University [Multimedia entry (ORO)] [Poster (ORO)]

% Burel G., Farrell T., Mensio M., Khare P., Alani H. (October 2020) Co-Spread of Misinformation and Fact-Checking Content during the Covid-19 Pandemic. In (SocInfo 2020) Social Informatics 2020 [Full text (ORO)] [Full text (Springer)]

% Piccolo L., Blackwood A., Farrell T., Mensio M. (July 2021) Agents for Fighting Misinformation Spread on Twitter: Design Challenges. In 3rd Conference on Conversational User Interfaces (CUI 2021) [Full text (ORO)] [Full text (ACM)]

% Denaux R., Mensio M., Gomez-Perez J., Alani H. (August 2021) Weaving a Semantic Web of Credibility Reviews for Explainable Misinformation Detection. In Thirtieth International Joint Conference on Artificial Intelligence (IJCAI-21) [Full text (ORO)] [Full text (IJCAI)]

% Reyero Lobo P., Mensio M., Pavon-Perez A., Bayer V., Kwarteng J., Fernandez M., Daga E., Alani H. (June 2022) Estimating Ground Truth in a Low-labelled Data Regime: A Study of Racism Detection in Spanish. In (ICWSM-22) First Workshop on Novel Evaluation Approaches for Text Classification Systems on Social Media (NEATCLasS) [Full text (ICWSM)]


% MARTINO MENSIO, GRÉGOIRE BUREL, TRACIE FARRELL, and HARITH ALANI. (June 2023) MisinfoMe: A Tool for Longitudinal Assessment of Twitter Accounts’ Sharing of Misinformation. In (UMAP 2023) The 31st ACM Conference On User Modeling, Adaptation And Personalization

% Martino Mensio, Grégoire Burel, Youri Peskine, Raphaël Troncy, Paolo Papotti, and Harith Alani. (November 2023).
% MisinfoKG - A Misinformation and Fact-Checks
% Knowledge Graph. In ISWC-2023 Resource Track
