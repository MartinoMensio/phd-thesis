\chapter{\statusgreen Introduction}
\label{chap:intro}

% Orientation: wider context

% situation
Thousands of articles are published every single day about the latest events happening.
The usage of specific language, the selection of details, and how the narrative is presented, are all different aspects that are unique to each news outlet and author.
These peculiarities, at the same time, can influence what the reader perceives about the events described.
% framing definition
This whole set of information, whether subtle or explicit, extends the raw facts that happen and are shared as ground truth between multiple sources. This additional layer, which varies between multiple news, appears with different names, such as \emph{framing}~\cite{gamson1989media,scheufele1999framing}, \emph{persuasion}, \emph{propaganda}, with slightly different definitions.
These persuasion techniques can be conveyed with any subjective statements that are mixed with the description of the event narrated, but it does not stop there.
% TODO reference: ``Various observers have noted how subtle framing subtly and unconsciously [framing] operates'' (Gamson and Modigliani, 1989, p. 7)
Even selecting which details or features to report greatly affects the message sent to the reader.

% introduce ideology/leaning
In this landscape of parallel news, there are multiple factors in play, such as political orientations and ideologies, that may influence the writing style of news outlets.
For example, persuasion may be used to push for political ideologies directly or subtly.

% introduce topics
The persuasion used may change with respect to the \emph{topic} of the news. Some topics are more polarising while others are more neutral.

% EXAMPLE NEEDED HERE

% % example
% For example, taking two sentences ``\textit{the black man was shot}'' vs ``\textit{the man was shot}'', they have a different framing because, although the man shot was black, it is a judgement of the reporter whether this detail needs to be emphasised or not, considering the ethnicity of the person who was shot to be important. %implying a form of racism with respect to a race-independent murder.

% Framing can have a big impact on the way readers perceive the content and relevance of the news~\cite{cohen2015press}. %(\textit{Agenda-setting}).

This thesis explores the relationships between persuasion, political orientation and topics.
These variables are studied independently in the existing literature, and this work aims at understanding the links between them.








% PhD Project done across \acrshort{kmi} and Computing\&Communications.

This chapter contains an introduction to the thesis.
Section~\ref{sec:intro_problem} contains the Problem Statement, Section~\ref{sec:intro_motivation} the Motivation, Section~\ref{sec:intro_rqs} contains all of our Research Questions. Then in Section~\ref{sec:intro_hyp} we present our hypotheses, in Section~\ref{sec:intro_method} the general methodology used. We end the chapter with the main contributions in Section~\ref{sec:intro_contributions}, %the structure of the dissertation in Section~\ref{sec:intro_structure} 
and the publications in Section~\ref{sec:intro_publications}.


\section{\statusgreen Problem Statement}
\label{sec:intro_problem}


% At the intersection with misinformation, political issues, ...
% Study on propaganda

In this thesis we analyse persuasion means, with a focus on propaganda, to understand how they relate to additional dimensions (topic, leaning, similarity).

The problem is that at the moment, to the best of our knowledge, there is no computational study that analyses the relationship between persuasion means, leaning, topics and similarity.

What makes news articles about the same issue different? 
Some studies focus on the surface level, by considering which details are included (corroborated) or omitted~\citep{bountouridis2018explaining}.

Then there is a second branch of research that instead investigates the usage of linguistic means, such as persuasion, propaganda, sentiment and emotions. This second group focuses on single articles analysed on their own, in order to build models to detect such linguistic means over news articles. This set of features is considered as a layer of framing/propaganda on top of the facts described, and it needs to be properly recognised.

Then a third group of works sees the problems by considering only the political leaning. Here we find approaches to recognise political leaning from news articles~\citep{baly2020we}, to provide balanced news feeds to users (e.g. AllSides, Blue Feed - Red Feed), to label the leanings of news sources (datasets e.g., Media Bias/Fact Check, AllSides).

And finally, the last group focuses on topic analysis. Researchers usually use this method to break down results based on topics, to get more fine-grained insights~\citep{zhang2023strategic}.
% TODO: FIND SOME EXAMPLES OF TOPICS ANALYSIS FOR PROPAGANDA, NOT COMPUTATIONAL.
But we do not find a computational approach or analysis that considers the topic as an additional variable to propaganda, leaning or similarity.


Between these multiple branches of research, we see potential links that are left unexplored.

For example, regarding the potential connection between propaganda and leaning, we may be interested in knowing \emph{what are the differences in persuasion/propaganda used by different political orientations?} or \emph{how can we automatically recognise political leaning from propaganda?}

% What is the relationship with the topics discussed?
Or if we consider the relationship between topics and propaganda, it would be really useful to understand which topics contain more propaganda and which topics have  more polarising propaganda. And adding also the leaning variable, to identify topics where propaganda is more distinguishable between political leaning. This would give insights both on the characteristics of propaganda with respect to topics described and leaning where the articles come from, both in terms of techniques used and specific terminology used. 

\subsection{\statusgreen Key concepts}

Here we describe the most important concepts that are touched in this thesis. For a complete list, please refer to the Glossary.

\leftskip=3em
\parindent=-3em

\textbf{Event}: \glsdesc*{event}\footnote{\url{https://dictionary.cambridge.org/dictionary/english/event}}.

\textbf{Parallel News}: \glsdesc*{parallel-news}

\textbf{Similarity / Variations}: The specific combination of \gls{corroborate}[d] and \gls{omit}[ted] details. Terms that change. Similarity metrics that score how similar/dissimilar articles are.

\textbf{Persuasion}: \glsdesc*{persuasion}

\textbf{Propaganda}: \glsdesc{propaganda}

\textbf{Political Leaning}: \glsdesc{political-leaning}

\textbf{Topic}: \glsdesc{topic}


\leftskip=0em
\parindent 1.5em


\section{\statusgreen Motivation}
\label{sec:intro_motivation}

% % Rationale: create a niche
% % TODO why spotting is useful: http://faculty.sites.uci.edu/polletta/files/2016/02/22A-Simple-Intervention-to-Reduce-Framing-Effects-in-Perceptions-of-Global-Climate-Change22.pdf

% % need of comparing multiple articles
% Spotting the occurrence of framing is therefore a very difficult task, even for humans~\cite{morstatter2018identifying}. Something that could help in this situation is looking at different sources and analysing how they present the same event with different framing.
% By seeing ``the other sides'' of the story, we, as readers, could create a more complete picture and spot the differences at the macro (the perspective of the overall article) and micro-level (specific linguistic cues)~\cite{gamson1989media}.
% The main problem with this technique is that it requires a lot of time,
% and many people only read news articles superficially% very lazy while consuming the news
% ~\cite{pennycook2019lazy}.
% % to read, compare, track, and differentiate all the small details \todo{any citation to support this statement?}.
% % tech limitations
% At the moment, we can see a gap in the tools available to provide this functionality automatically.
% Some technologies analyse parts of the problem, e.g. by grouping articles together by events (news aggregators), or anti-plagiarism tools that spot sentences occurring in multiple documents, or theoretical studies and conceptualisations analysing framing under different aspects.
% But to our knowledge, none of them is bringing together different stories to highlight the framing differences automatically.


% % Aim: purpose of research

% This PhD aims at creating a methodology to extract and characterise framing differences among news articles.
% This includes on one side revealing the choices done by the authors, and bring to the light the types of techniques they use to stand their point of view (e.g., selection and emphasis of details, addition of subjective content).
% And on the other side, to study the information flow between sources and see which relationships exist between them. %(e.g., reusing content).


% Who can find this thesis useful?
% The motivations of this thesis are multiple.

By analysing the relationship between propaganda, political leanings and topics, we aim to understand how strongly they are linked together. There is a wide literature, both theoretical and practical, about each of these factors.
And on the theoretical/qualitative research level, there are some works that explain and motivate this relationship by analysing a specific event or timeframe~\citep{pierri2023propaganda,golovchenko2020cross,blumberg1986comparative}.
But on the practical side, we find a lack of computational approaches that consider these factors together.

A computational approach, which considers together document similarity, propaganda, leaning and topics, would be of great utility to different groups of stakeholders:

\begin{enumerate}
    \item Computational Researchers:
    \begin{enumerate}
        \item Verify / refute the relationship between political leaning and propaganda. The literature assumes that the political ideology of news writers/editors conditions how news articles are written considering economic reasons, unconscious  assumptions and reporters-sources relations that are linked to political leanings~\citep{schudson2002news}. And these factors result in news articles that contain more or less subtle persuasion devices for the reader (one of which is propaganda). By analysing and quantifying these relationships, we can understand their weight. % contribution 1: compute weights of these relationships, understand better the relationships
        \item By using together these variables, we can try to improve some automated approaches that currently rely on just one input feature, such as political leaning classification using propaganda and topic features. By exploiting the relationship between these features, we can help \acrfull{ml} models to have higher values for the target metrics. % contribution 2: improve F1 using mix of feature
        \item With an analysis that considers multiple variables, we may discover problems and inconsistencies that can only be discovered with combined analyses (e.g., data imbalance). This is a very important point when using \acrshort{ml}-based approaches, as improving the quality of the data is a key element. % contribution 3: We highlight the problem of imbalanced dataset for propaganda detection
    \end{enumerate}
    \item Users reading the news:
    \begin{enumerate}
        \item link and show similarities to other documents on how the same topic is covered. Especially articles from other political leanings which may have a different angle.
        \item support with a tool to highlight propaganda, to be conscious of the techniques used in the articles at the word level. It is crucial for this analysis to be as accurate as possible, and that is why we aim to find insights which may help create or extend datasets (e.g., in the case of unbalanced datasets).
        \item understand better how propaganda distributes across leanings and topics, to be able to recognise more manipulation and be less manipulable.
    \end{enumerate}
\end{enumerate}


% Motivation/Orientation: multiple narrations of the same events. Driven by multiple factors (selection criteria, point of view of author/publisher, relevance, agenda-setting, …)
% This is linked with Persuasion, but more specifically propaganda. Communication with the goal to persuade. Subtle or more explicit.
% What distinguishes one piece of news from the others about the same event? 

% Political ideology → writer/editor → news (facts + propaganda(opinion)) → persuasion of reader

% Rationale (niche): computational propaganda detection is at an early stage in the research community. Current detection is based on unbalanced datasets that particularly target right-leaning news.

% Aims/Goals of this thesis: 
% understand how propaganda varies across the political spectrum
% Computational perspective: is propaganda detection ready to work in news independently from the political orientation/leaning of the source?




\section{\statusgreen Research Questions}
\label{sec:intro_rqs}

Given this aim, we build a research path that gradually adds the different variables.

\begin{enumerate}
    \item We start from the first factor of similarity (and differences) between news articles, which is the motivation for our work in the first place. Being able to analyse the similarities and differences enables us to get a grasp on what effectively changes between related articles. Therefore, our first \acrfull{rq} is \emph{RQ1: What makes news articles about the same issue different?}
    \item Then, we move our focus to the computational detection of persuasion techniques. How they can be detected, and what is the relationship to our first \acrshort{rq}1. This constitutes for us \emph{\acrshort{rq}2: How can we automate the detection of persuasion techniques used by writers and assess their impact on recognizing related news articles?} 
    \item Afterwards, we introduce the variable of political leaning, to understand how it relates to persuasion. This leads us to \emph{\acrshort{rq}3: How does persuasion vary across the political spectrum, and can we predict a news article's political leaning based on its propaganda techniques?}
    \item Finally, we introduce the topic as the last variable, to break down the results found in the previous investigation. This is our \emph{\acrshort{rq}4: How does the detected propaganda vary across topics and political leanings, and what is the impact of combining propaganda and topic features on accurately determining the political leaning of a news article?}
\end{enumerate}

We dedicate an experimental chapter to each of the \acrlong{rq}s: from Chapter~\ref{chap:common_ground_search} to Chapter~\ref{chap:topics}.
% Each of them is split into sub-questions, that we list and describe here to present all of them together.
Each one of them contains several sub-questions that we list here for comprehensiveness.


\subsection*{RQ1: What makes news articles about the same issue different?}

We are interested in how can we analyse and compare multiple sources to identify unique perspectives and overlapping information, detect omissions and corroborations, and select effective similarity metrics.
The sub-questions are the following:
\begin{enumerate}[label={\textbf{RQ1.\arabic*:}},leftmargin=2cm]
    \item How do different sources present the same events?
    \item Can we analyse what is unique from each version and what overlaps? 
    \item How can we automatically detect omission and corroboration across multiple articles?
    \item How can we select better similarity metrics to empower omission and corroboration detection?
\end{enumerate}

These questions are targeted in Chapter~\ref{chap:common_ground_search}.

\subsection*{RQ2: How can we automate the detection of persuasion techniques used by writers and assess their impact on recognizing related news articles?}

This second \acrlong{rq} introduces the variable of persuasion techniques and has the following sub-questions:

\begin{enumerate}[label={\textbf{RQ2.\arabic*:}},leftmargin=2cm]
    \item How could we automatically detect the persuasion techniques used by writers?
    \item Which persuasion techniques do we detect most frequently?
    \item How are the differences between similar articles related to a different use of persuasion techniques?
    \item how much of an obstacle is persuasion in recognising articles that are related to the same news? (rewrite)
\end{enumerate}

These are answered in Chapter~\ref{chap:linguistic_persuasion}.

\subsection*{RQ3: How does persuasion vary across the political spectrum, and can we predict a news article's political leaning based on its propaganda techniques?}

We introduce with this question the political leaning variable, to do a comparative analysis of propaganda with respect to it. The sub-questions are:

\begin{enumerate}[label={\textbf{RQ3.\arabic*:}},leftmargin=2cm]
    \item How does persuasion vary across the political spectrum?
    \item To what extent can we predict the political leaning of a news article by observing the propaganda it uses?
    \item Is Propaganda Detection balanced? Or is there some imbalance in the datasets used in the literature?
\end{enumerate}

This is analysed in Chapter~\ref{chap:political_sides}.

\subsection*{RQ4: How does the detected propaganda vary across topics and political leanings, and what is the impact of combining propaganda and topic features on accurately determining the political leaning of a news article?}

This last question introduces the political leaning variable, and is split into three sub-questions:

\begin{enumerate}[label={\textbf{RQ4.\arabic*:}},leftmargin=2cm]
    \item How does the detected propaganda change across the topics? Are there major differences when considering “polarised” topics with respect to more neutral topics?
    \item How does the detected propaganda change across leanings in “polarised” topics? And how does it change in non-polarised ones?
    \item What are the effects of combining the propaganda features with the topic features, to recognise the leaning of a news article?
\end{enumerate}

This is answered in Chapter~\ref{chap:topics}.


% What is the relationship between propaganda and political leaning?
% Diffusion
% Does propaganda exist all across political leaning?
% Do existing propaganda datasets represent each leaning well?
% (Why is there this discrepancy between i) and ii)?)
% Term usage
% What terms are used in propaganda?
% Do different leanings use similar propaganda terms?
% Populism
% Is propaganda correlated to populism in literature?
% Does the correlation show up in the data?
% Topics (?)
% How is propaganda spread across topics (overall)?
% Do different leanings use propaganda with different topics?
% Targets of propaganda (?)
% Who are the targets of propaganda (overall)?
% Do different leanings have different targets of propaganda?
% Prediction
% Is it possible to predict the political leaning of an article from its propaganda features?
% By removing propaganda terms from articles? 



\section{\statusgreen Research hypotheses}
\label{sec:intro_hyp}

This thesis is based on several hypotheses coming from the literature analysis.
% Most of them come from the literature, mixed with common knowledge.

% layers of info and choice of terms
\emph{HYP1:} News articles are made with different layers of information: (i) facts and events (ii) interpretation/persuasion.
These layers are not separate and are very intertwined. On the word level, we have words that are strictly topical words, or are strictly persuasive words, but we also have words that represent both layers as a specific term is chosen in a multitude of synonyms to push for a certain idea.
We find this hypothesis in~\citep{jenkins2013thin,vanderwicken1995news,jang2023proximate}.

% corroboration and choice of details
\emph{HYP2:} News articles are written by choosing which details to include and which ones to skip, and this may be done on purpose to influence the reader. This assumes that there are multiple details to choose from, and the news outlets (writer/editor) need to do a selection for fitting in the desired length or more directly support a certain position. And everywhere manual selection is done, there is a possible point of bias. This hypothesis is described in~\cite{bountouridis2018explaining} while trying to computationally use it to detect corroborations and omissions.

% propaganda and leaning
\emph{HYP3:} Propaganda language used by different political leanings is distinguishable. This means that Left and Right leaning have specific techniques or wordings that they use for example to target political opponents. Literature shows this~\citep{blumberg1986comparative}, but we want to detect computationally such techniques and wordings.

% % unbalance
% Current propaganda detection recognises better right-leaning propaganda

% TODO: add others?

% We have more specific hypotheses in the following experimental chapters.

\section{\statusgreen Research methodology}
\label{sec:intro_method}

On a broad level, our methodology is a comparative analysis of propaganda across multiple dimensions (leaning, topic).

As we described in the previous sections, methodologically we take one concept at a time and we add it to our analysis. For this reason, Chapter~\ref{chap:common_ground_search} treats similarity and overlap between multiple articles, then Chapter~\ref{chap:linguistic_persuasion} moves to linguistic means of persuasion. The chapters afterwards add Leaning (Chapter~\ref{chap:political_sides}) and Topics (Chapter~\ref{chap:topics}) to the comparative analysis. In this way, we start with simpler conditions without many variables into play, and we gradually add the additional variables as we need them to break down the results and find correlations between the factors considered.


If we go into more detail about the single experiments done in the thesis, we use several methodologies across the chapters:
\begin{itemize}
    \item classifier-based: for a big part of our experiments, we use a methodology that is usually employed with classifiers. This is based on the computation of a metric (macro F1 in this case) of how well the classifier is able to predict the correct label for the inputs (in this case news articles). We use this setup with a classifier to understand the impact of multiple input variables (text of the articles, propaganda features, topic labels) on predicting the correct political leaning of the articles (taken as ground truth). In addition, this setup allows doing a \emph{confusion analysis}, to understand the labels that have been wrongly predicted. And depending on the model used, we can also perform a \emph{feature importance} analysis to understand how strongly the features are used to make the prediction (what the model learns). This methodology is usually accompanied by a significance test, which establishes the probability of the observed improvement happening by chance.
    \item comparative analysis: we have many analyses in Chapter~\ref{chap:political_sides} and \ref{chap:topics} where we use comparative analysis to compare the distribution of one observed variable across multiple controlled variables. This methodology relies on aggregated metrics (such as average, median and standard variation) on a specific variable (e.g. quantity of a propaganda technique) to compare groups of articles and observe differences. We extract patterns of association between variables and observations from statistics compared between the groups.
\end{itemize}


\section{\statusgreen Contributions}
\label{sec:intro_contributions}

The major contributions of this work are the following:
\begin{enumerate}
    \item contribution 1: computing weights and better understanding the relationships between the multiple dimensions of similarities, propaganda, leaning and topics. This is achieved with:
    \begin{enumerate}
        \item Chapter~\ref{sec:lp_relationship} contains an analysis of the relationship between persuasion and the word variations that different news sources produce when reporting events.
        \item Chapter~\ref{chap:political_sides} shows, by improving the classifier values of F1 metric, that propaganda and political leanings are slightly correlated. If they were not correlated, adding propaganda as input feature would have no effect.
        \item Chapter~\ref{chap:topics} finds that the topic is highly correlated with propaganda: some topics have very high levels of propaganda, while other ones are less polarizing and contain less of it. And considering the terms of propaganda, we find that for some topics they are very different between political leanings. %This not only means that the correlation between topics, leanings and propaganda is high, but it also means that
        %Certain topics have more propaganda on a specific leaning. This happens with topics that are more important from the considered point of view, or where the considered leaning is currently against the status quo.
        % \item Distribution of propaganda techniques is very similar across leanings for most of the topics (relative ratio of the quantity of techniques between themselves). Combined with the previous finding, it means that the quantities of the techniques scale proportionally across leanings in most of the topics.
        % \item Terms of propaganda can be quite different across political leaning in certain topics. For some of these topics, they already have an imbalance of total quantity (e.g. Left has more propaganda than Right), for some others, the quantity is very similar, but they differ in the terms used.
        % \item For a set of topics, it is easier to classify correctly the political leaning than in others. The easiest topics are the ones that are more polarised.
        % \item Adding propaganda features to the baseline model has a positive impact on prediction metrics on major topics, while for some topics instead, it has negative impacts.
        
    \end{enumerate}
    \item contribution 2: improving F1 of the political leaning classifier using a mix of features. More specifically:
    \begin{enumerate}
        \item Chapter~\ref{ssec:ps_prop_leaning_classifier}  shows that if we add propaganda features on a BERT-based classifier that predicts political leaning, we get slightly better results that are significant according to McNemar tests. In these cases, the propaganda features help to correct some imbalances of the baseline classifier. However, the number of samples affected is quite small.
        \item Chapter~\ref{chap:topics}: adds the topic and uses it as a feature for the classifier. The result is an increase in the prediction metrics, small but significant.
    \end{enumerate}
    \item contribution 3: highlighting the problem of imbalanced dataset for propaganda detection. This emerges from the analysis in different chapters:
    \begin{enumerate}
        \item Chapter~\ref{chap:linguistic_persuasion} results in a deeper understanding of the limitations of the current status of this automated detection (of propaganda), and the repercussions it can have when we use these methods in other tasks (e.g. overlap across news articles).
        % Computational detection of persuasion means is quite a recent research area, and with time and more resources (datasets and models) it could clearly improve
        \item Chapter~\ref{chap:political_sides} analyses and finds a big imbalance of propaganda detection datasets considering political leaning. Almost only Right-leaning articles are used in the current literature.
        % First of all, they show how current propaganda detection is able to work with articles coming from very different political orientations. We think that the results here found are demonstrating quite good abilities to generalise from the relatively small datasets used for training propaganda.
        % And if we consider that a big proportion of the news used in our experiments comes from a different political leaning, we think that these are very promising results.
        % We were able to extract, analyse and link to our external knowledge of the events and ideologies. This is a very positive outcome.
        \item Chapter~\ref{chap:topics} expands on this imbalance and finds topics that contain more or less propaganda generally or in a specific political leaning.
    \end{enumerate}

    
    % \item Chapter 3: As already denoted by the work of~\citet{bountouridis2018explaining}, we confirm a positive correlation between corroboration and credibility of news outlets and a negative correlation between omission and credibility. We went one step further, by being able to automatically find the specific words that change between multiple news articles, and identify the degree of uniqueness of them. We think that this is beneficial for many downstream tasks, such as showing to the user during annotation tasks or even when consuming news online. 
    % \item Observing similarities between multiple documents is made very difficult by linguistic variations. We experimented with models (e.g. \acrshort{use}) that are more resistant to words that carry similar meanings and are a better fit for doing this type of analysis.


    % \item Chapter 4: chapter highlighted how, by integrating the automated detection of persuasion in news articles, we have on one side a clearer idea of the relationship between persuasion and the variations that different news sources produce when reporting events.
    % \item On the other side, we have also a deeper understanding of the limitations of the current status of this automated detection, and the repercussions it can have when we use these methods in other tasks.
    % Computational detection of persuasion means is quite a recent research area, and with time and more resources (datasets and models) it could clearly improve

    % \item Chapter 5: % - positive: generalisation quite good considering datasets and results obtained
    % First of all, they show how current propaganda detection is able to work with articles coming from very different political orientations. We think that the results here found are demonstrating quite good abilities to generalise from the relatively small datasets used for training propaganda.
    % And if we consider that a big proportion of the news used in our experiments comes from a different political leaning, we think that these are very promising results.
    % We were able to extract, analyse and link to our external knowledge of the events and ideologies. This is a very positive outcome.

    % - finding TOPICS where difference is more accentuated
    % At the same time, this chapter has also helped us to find a direction for more investigation. The results found here represent the whole dataset. We would like to know if we can spot more in details the differences of propaganda when we consider specific topics separately. Propaganda may differ between political leanings more when we select certain topics, and we would like to know both which topics and also the outcomes of such a detailed analysis. And for conducing this experimentation, we need to consider the \emph{topics} of the articles as an additional element.

    % \item Chapter 6: \item We need fine-grained topic to be able to see differences. The coarse topics show similar propaganda across topics and leanings. The more we use fine-grained topics, the more differences we are able to see. But at the same time, we lose support (fewer articles specific to the topics, and the filtering becomes too narrow). We need a tradeoff between granularity (high to see good differences) and support (significance of results).
    % \item Certain topics have more propaganda on a specific leaning. This happens with topics that are more important from the considered point of view, or where the considered leaning is currently against the status quo.
    % \item Distribution of propaganda techniques is very similar across leanings for most of the topics (relative ratio of the quantity of techniques between themselves). Combined with the previous finding, it means that the quantities of the techniques scale proportionally across leanings in most of the topics.
    % \item Terms of propaganda can be quite different across political leaning in certain topics. For some of these topics, they already have an imbalance of total quantity (e.g. Left has more propaganda than Right), for some others, the quantity is very similar, but they differ in the terms used.
    % \item For a set of topics, it is easier to classify correctly the political leaning than in others. The easiest topics are the ones that are more polarised.
    % \item Adding propaganda features to the baseline model has a positive impact on prediction metrics on major topics, while for some topics instead, it has negative impacts.
    % \item Encoding the topic information and using it as a feature, helps increase the prediction metrics of a leaning classifier. The improvements are small but significant.

    
    % \item Topics where current automated propaganda detection is more problematic (TODO) 
    % \item Link between propaganda and political leaning is weak (not enough to identify leaning by just looking at the propaganda techniques) → against HYP1
    % \item Imbalance is / is-not a problem for propaganda detection
\end{enumerate}





% \section{\statusred Structure of the dissertation}
% \label{sec:intro_structure}

% ALREADY DONE WITH RQ AND METHODOLOGY, USELESSS TO REPEAT

% Chapter~\ref{chap:literature} literature.

% Then chapters 3-6 experimental:

% Chapter 3: Common Ground Search,
% Chapter 4: Linguistic Proxies of Persuasion,
% Chapter 5: Perspectives and Political Sides,
% Chapter 6: Topics.

% Chapter~\ref{chap:discussion}: discussions and conclusions.

\section{\statusgreen Publications}
\label{sec:intro_publications}

During the timeframe of this PhD, multiple publications have been accepted at workshops and conferences. Some of them are strictly related to the topic of this thesis~\citep{mensio2020towards}, while others are not directly linked to the topics here presented but still in the same broad research area of news analysis, news media and the response of the public to manipulation and misleading information (under the measure of Credibility).

% \subsection{Related to this thesis}

% Towards a Cross-article Narrative Comparison of News
% M Mensio, H Alani, A Willis
% Proceedings of the Text2Story’20 Workshop

% Mensio M., Willis A., Alani H. (April 2020) Towards a Cross-article Narrative Comparison of News. In Third International Workshop on Narrative Extraction from Texts held in conjunction with the 42nd European Conference on Information Retrieval (Text2Story2020 @ ECIR2020) [Full text (ORO)] [Full text (CEUR)] [Presentation slides]

% \fullcite{mensio2020towards}
\begin{itemize}
    \item \bibentry{mensio2020towards}
    \item \bibentry{mensio2020one}
    \item \bibentry{mensio2019news}
    \item \bibentry{mensio2019misinfome}
    \item \bibentry{mensio2020mitigating}
    \item \bibentry{mensio2023misinfome}
    \item \bibentry{burel2020co}
    \item \bibentry{piccolo2021agents}
    \item \bibentry{denaux2021weaving}
    \item \bibentry{lobo2022estimating}
    % \item \bibentry{mensio2023misinfokg}
\end{itemize}





% We present an idea for a system to perform cross-article narrative comparison.


% Mensio M., Alani H., Willis A. (June 2020) One Event, Different Stories. In Postgraduate Research Poster Competition 2020, The Open University [Multimedia entry (ORO)] [Poster (ORO)]



% \subsection{Other publications during the timeframe}

% Mensio M., Alani H. (October 2019) News Source Credibility in the Eyes of Different Assessors. In Conference for Truth and Trust Online (TTO 2019), London, UK [Full text (ORO)] [Full text (Conference)] [Slides]

% Mensio M., Alani H. (October 2019) MisinfoMe: Who’s Interacting with Misinformation? In (ISWC 2019) Posters and Demos [Poster] [Full text (ORO)] [Full text (CEUR)]


% Mensio M., Bastianelli E., Tiddi I., Rizzo G. (March 2020) Mitigating Bias in Deep Nets with Knowledge Bases: the Case of Natural Language Understanding for Robots. In AAAI 2020 Spring Symposium on Combining Machine Learning with Knowledge Engineering [Full text (CEUR)]

% Mensio M., Willis A., Alani H. (April 2020) Towards a Cross-article Narrative Comparison of News. In Third International Workshop on Narrative Extraction from Texts held in conjunction with the 42nd European Conference on Information Retrieval (Text2Story2020 @ ECIR2020) [Full text (ORO)] [Full text (CEUR)] [Presentation slides]

% Mensio M., Alani H., Willis A. (June 2020) One Event, Different Stories. In Postgraduate Research Poster Competition 2020, The Open University [Multimedia entry (ORO)] [Poster (ORO)]

% Burel G., Farrell T., Mensio M., Khare P., Alani H. (October 2020) Co-Spread of Misinformation and Fact-Checking Content during the Covid-19 Pandemic. In (SocInfo 2020) Social Informatics 2020 [Full text (ORO)] [Full text (Springer)]

% Piccolo L., Blackwood A., Farrell T., Mensio M. (July 2021) Agents for Fighting Misinformation Spread on Twitter: Design Challenges. In 3rd Conference on Conversational User Interfaces (CUI 2021) [Full text (ORO)] [Full text (ACM)]

% Denaux R., Mensio M., Gomez-Perez J., Alani H. (August 2021) Weaving a Semantic Web of Credibility Reviews for Explainable Misinformation Detection. In Thirtieth International Joint Conference on Artificial Intelligence (IJCAI-21) [Full text (ORO)] [Full text (IJCAI)]

% Reyero Lobo P., Mensio M., Pavon-Perez A., Bayer V., Kwarteng J., Fernandez M., Daga E., Alani H. (June 2022) Estimating Ground Truth in a Low-labelled Data Regime: A Study of Racism Detection in Spanish. In (ICWSM-22) First Workshop on Novel Evaluation Approaches for Text Classification Systems on Social Media (NEATCLasS) [Full text (ICWSM)]


% MARTINO MENSIO, GRÉGOIRE BUREL, TRACIE FARRELL, and HARITH ALANI. (June 2023) MisinfoMe: A Tool for Longitudinal Assessment of Twitter Accounts’ Sharing of Misinformation. In (UMAP 2023) The 31st ACM Conference On User Modeling, Adaptation And Personalization

% Martino Mensio, Grégoire Burel, Youri Peskine, Raphaël Troncy, Paolo Papotti, and Harith Alani. (November 2023).
% MisinfoKG - A Misinformation and Fact-Checks
% Knowledge Graph. In ISWC-2023 Resource Track
