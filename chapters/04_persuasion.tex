\chapter{\statusgreen Linguistic Techniques of Persuasion}
\label{chap:linguistic_persuasion}

\section{\statusgreen Introduction}
\label{sec:lp_intro}

% what (orientation)
In this second experimental chapter, we introduce a new ingredient in our analysis: persuasion techniques.
% \todoHA{wasn’t this already introduced in chapter 3?}
With the previous Chapter~\ref{chap:common_ground_search}, we underlined our need to understand how different terms, that are used to describe the same details, can effectively convey a different message to the readers.
Therefore, in order to characterise those differences, this chapter introduces \gls{persuasion} as an umbrella term that encompasses several techniques where the writer of a piece of text is trying to push to the reader a certain point of view.
% In this chapter, we add our second ingredient: persuasion.\todoAW{abrupt start}
% We intend persuasion as a general umbrella that encompasses several techniques where the writer of a piece of text is trying to persuade the reader of a certain point of view.

% why (rationale)
From the last chapter~\ref{chap:common_ground_search},
%we concluded with the need to understand how specific terms are used to persuade the reader. 
we are able to extract terms that have been changed in related articles, from sentences that are very similar but have still some differences.
Our aim is here to quantitatively analyse these detected variations to quantify their specific use of persuasion techniques.
% \todoHA{Why? What is the value of this detection?}
In this way, we could understand if the specific term choices are in fact done to persuade the reader of a specific idea, or if they are only the manifestation of random choices.

For this reason, this chapter investigates the \emph{linguistic techniques of persuasion}, in other words, how the persuasion manifests itself on the linguistical surface.
% aim
Our motivation is to analyse whether the terms that change between multiple articles/sentences are correlated with the linguistic techniques of persuasion.

The Research Questions for this chapter is \acrshort{rq}2: \emph{To what extent can we automatically detect the persuasion techniques used in news articles?} It is split into four subquestions:
\begin{enumerate}[label={\textbf{RQ2.\arabic*:}},leftmargin=2cm]
    \item To what extent could we automatically detect the persuasion techniques used by writers? % Which are the possible indicators of these differences? // 
    \item Which persuasion techniques are detected more frequently than others?
    \item How do similar news articles differ in their use of persuasion techniques? %\emph{How are the differences between similar articles} (extracted in the previous chapter) \emph{related to a different use of persuasion techniques?} % Is there a link between the parts that are different and persuasion techniques (propaganda/loaded language)? // 
    \item To what extent could persuasion techniques be used to identify related news articles?%If the same story can be narrated differently depending on the persuasion techniques used, then persuasion is adding variations to the narration. Therefore, \emph{how much of an obstacle is persuasion in recognising articles that are related to the same news?} %(clustering) % how much of an obstacle is persuasion in recognising the events in multiple articles?
          %\todoHA{What led to this RQ? Previous text does not lead to this}
\end{enumerate}


% method
% strong/loaded language: using sentiment analysis tools 
% 18 techniques of propaganda

% Experiment together with common ground search
To answer these research questions, we take from Chapter~\ref{sec:lit_persuasion} the most commonly and recently analysed \gls{persuasion} techniques for which computational detection methods exist: \gls{propaganda} and \gls{sentiment}.
%\todoAW{Slightly weird phrasing here... have you run this through Grammarly?}
%\todoHA{Any refs that link propaganda and sentiment with persuasion?}
% \todoAW{Harith asks what links propaganda, sentiment and persuasion. I'd ask what separates them. ie. why do you need to study persuasion at all if you can detect the other two cases?}
% \todomargin{MM: Persuasion including both, needed a term to simplify instead of always saying propaganda and sentiment}

% BEGIN response to HA
As discussed in Chapter~\ref{sec:lit_persuasion}, we consider here \gls{persuasion} as a term that encompasses both \gls{sentiment} and \gls{propaganda}. % and populism
It is linked with sentiment because of its goal to influence the emotional response~\citep{gatti2014sentiment,rocklage2018persuasion,petty2015emotion,desteno2004discrete}.
The relationship with propaganda comes from the inherent goal of propaganda to influence the view of the public about an idea or a group~\citep{bernays,jowett2018propaganda}.
%\todoAW{Good early citation shows you're aware of the broader literature... do you have others elsewhere in the dissertation? If not, probably worth making sure you're aware of some of the key authors in the area. Three or four should be enough.}

% It is known that persuasion is related to an emotional response from the reader/listener, being related to emotions.
% Persuasion and Discursive Repertories~\citep{orrumachine}
% propaganda is a``consistent, enduring effort to create or shape events to influence the relations of the public to an enterprise, idea or group''~\citep{bernays}.
% Persuasion and Propaganda: ~\citet{jowett2018propaganda}.
%, populism.
% END response to HA


% carry the following experiment:
Therefore, after describing the used datasets in Section~\ref{sec:lp_datasets}, we have the first part of this chapter that covers the detection of these persuasion techniques (Section~\ref{sec:lp_techniques}).
Afterwards, in Section~\ref{sec:lp_relationship} we put this in relationship with the analysis from the previous Chapter~\ref{sec:cgs_clustering_and_differences}. % Chapter~\ref{chap:common_ground_search}
We extend the study to consider the terms that change between articles, and we analyse whether they are associated with some persuasion techniques, and in what way. %indicate something about the changes in the sentences.

In order to achieve this goal, we consider in this chapter the following processing pipeline:
\begin{enumerate}
    \item Analysis from Chapter~\ref{chap:common_ground_search}: extracts the words that are changed between similar sentences of similar articles.
    \item Extraction of different techniques (sentiment, propaganda) on the sentences (described in the next Section~\ref{sec:lp_techniques}). %\todoAW{Doesn't your earlier paragraph suggest that we've already got this? ("means for which we have computational detection methods: propaganda and sentiment"))}
    \item Analysis of the relationship between these techniques and the changes in the sentences (described in Section~\ref{sec:lp_relationship})
\end{enumerate}


% findings
We discover that
the initial methods for fine-grained propaganda detection seem to be more promising %\todoHA{How? In what way?}
than sentiment detection.
Fine-grained propaganda analysis gives a multidimensional result because it provides the amount and words for each specific technique. Instead, sentiment only provides a mono- (or bi-) dimensional result. Furthermore, it shows weaker results, as will be shown in the next sections: sentiment detection produces many words that are \emph{false positives}, and it becomes more difficult to understand which outputs we can rely on.
% Sentiment is (cor)related to the specific propaganda technique of \texttt{Loaded\_language}, and having one technique instead of $18$ is only a disadvantage.
% does not provide useful insights when observed together with the changes occurring in the articles. 
The multi-dimensionality of propaganda across the techniques is much more useful and also more precise.
For this reason, we mainly use propaganda for the experiments of the following chapters.
% \todoHA{I agree with AW. 
% also, you had a pipeline in the previous version. why removed? 
% good to tell the reader what steps you’ll be taking and why, before getting into all the detail. 
% }

% pointers to next sections
% The next sections are organised as follows. Section~\ref{sec:lp_techniques} contains the analysis of persuasion techniques: sentiment and propaganda.
% \todoAW{You've already told me this...}
% %some techniques that we identifed being related to persuasion.\todoAW{? I don't know what you mean by "related to" here.}
% We present what they are able to detect on our datasets. %(stage 2 of the pipeline above described).
% Then Section~\ref{sec:lp_relationship} contains two experiments aimed at understanding the relationship between these techniques and the words changed.%(stage 3 of the pipeline).

\section{Datasets}
\label{sec:lp_datasets}

In this chapter, we make use of several datasets.
First, we use them to understand how the detection of persuasion techiques works: Section~\ref{sec:lp_techniques} covers sentiment and propaganda detection, and we use different datasets to get some statistics about the detection itself.

Then, in Section~\ref{sec:lp_relationship}, we have two different experiments that cover the relationship between persuasion techniques and variations between similar articles.

Some of these datasets were already used in the previous chapter, and some of them are instead being generated with the methodology described in the previous chapter.

% \subsection{Sentiment analysis}

% % Datasets: AllSides, AllNews
% First of all, as described also in the previous chapter, we rely here on two datasets: AllSides and AllNews.

\subsection{AllSides}

The first dataset that we use, as in the previous chapter, is AllSides.
% \todoHA{so not all datasets here are different. you. may want to change the earlier statement then to be more accurate}
This dataset contains articles that are grouped in “headlines” (3 articles for each headline) and each headline belongs to one of the 326 topics (almost all political-related). There are (updated 26th October 2022) 5124 headlines, for a total of 15050 articles. They are grouped in triples, called \emph{headlines}. Each triple belongs to one of several topics, which can be seen as more loosely-grained clusters.
As positive side,
%it ishuman-curated,\todoHA{rewrite more clearly}
%meaning that 
it is not the result of an algorithm (like Google News) but some curators manually grouped the articles.
% Therefore, the groups of articles could be considered of high quality.
% \todoHAinline{note that we can't say for sure since we know nothing about who these curators are, how many contributed to the grouping, did they disagree or not, etc. We assume quality since this is a public and known website but we need to do some evaluation to be more certain. This could go into your discussion section.}
Furthermore, this resource is publicly available, as the AllSides website provides the Headline Roundups.\footnote{\url{https://www.allsides.com/headline-roundups}}

% On the negative side, although the data is public, it is licensed and furthermore the articles are just linked and not included.
% This means that for collecting it, we need to manually retrieve the contents of the pages externally linked, which incurs in additional scraping problems and licensing problems.
% \todoHAinline{the license issue is not related to this analysis, so move it to the discussion section. As for the need to collect the articles, again, this is not a negative side. It's just a task you need to do. Try not to throw negativity into your work so early on. Rewrite}

% Another negative side,\todoHA{this is a limitation, not a negative side}
As a limitation, there are only three articles for each headline, so we do not expect to find a lot of linguistic variations, especially if we are strict on only having highly similar sentences. For this reason, it would be difficult to use it in the experiment detailed in Section~\ref{ssec:lp_relationship_small_variations} that requires fine-grained difference analysis.
Instead, we use it in the experiment of Section~\ref{ssec:lp_relationship_removing} that works on the article level only.
% sides: human-curated, public. Negative sides: only 3 articles for each headline. But for each topic, there are 46 articles on average.

\subsection{All-the-News}

Another dataset that we use throughout this chapter, is \emph{All-the-News}.\footnote{\url{https://www.kaggle.com/datasets/snapcrack/all-the-news}}
As described in the previous chapter, this dataset includes more than 140k articles published by fifteen major US outlets.
% The second one, AllNews, is much larger as it includes 2.7 million news articles, published between January 2016 and April 2020.\todo{finish} --> new version has milions

% Something specific for this chapter: used because it has larger quantity of articles
Therefore, we use it because it has a larger quantity of articles than AllSides. We use it in Section~\ref{sec:lp_techniques} to do a larger analysis of how the detection of the persuasion techniques works.

However, it has also some disadvantages, as the articles are not grouped together by topic or headline.
This means that this resource is less suitable for the experiments in Section~\ref{sec:lp_relationship}, that instead need to start with groups of articles.

\subsection{Small Variations Dataset}
\label{ssec:lp_relationship_small_variations_data}

Here we introduce our own dataset, that is created to analyse the small variations between similar sentences.
This dataset is derived from Google News Headlines (described in the previous chapter), and consists of pairs of sentences (extracted from the analysis of chapter~\ref{chap:common_ground_search}) which are characterised by high similarity score (\acrshort{use} model).

The dataset of origin is Google News Headlines, as it presents clusters of articles with a high number of articles each (between 20 and 90). Therefore, applying the methodology described in Section~\ref{sec:cgs_clustering_and_differences}, with quite strict thresholds on the distance between sentences, we can still produce in output many groups of sentences. These groups contain sentences that have minimal variations, and in Section~\ref{ssec:lp_relationship_small_variations} we aim to understand how these variations are related to a different usage of persuasion.
% Google headlines: articles are grouped in clusters. Clusters have around 20-90 articles each. Each cluster belongs to a certain broader topic (UK, World, Business, Entertainment, Sports, Science, Health). Positive sides: very large. Negative side: the clusters change over time, they are created by ML (not human-curated)

The Google News Headlines that we selected are between 8th September and 14th October 2020,
%\todoAW{OK, but be prepared to talk about whether you should have done a later version of the experiment. That will be a minimum of 2 1/2 years prior to the viva.} 
because that is the timespan during which this experiment was conducted, but it could be repeated in other timespans.
We extracted from them a subset of 138 sentence pairs, by using the approach described in the previous Chapter~\ref{sec:cgs_clustering_and_differences}:
\begin{enumerate}
    \item Random headlines (groups of articles) are selected. Their articles are segmented into sentences and each sentence is embedded with the \acrshort{use} model.
    \item Groups of sentences are extracted using \acrfull{hac}, to be able to use a similarity threshold to cut the dendrograms at any point. The features are the embeddings of point 1.
    \item We select thresholds for the clusters: minimal of $80\%$ and maximum of $98\%$ cosine similarity. In this way we select sentences that are related to the same detail (discarding sentences that are too different), but at the same time we discard sentences that are almost identical and only differ by punctuation.
    \item We randomly select a small subset of sentence pairs. From each cluster of sentences (containing three or more), only two sentences are selected in order to avoid having three-way comparisons (or even higher grade).
          %\item Manual annotation of whether the differences in the sentence pairs are making use of different persuasion or relate to a different opinion / point of view. This specific data is used for the experiments ``comparison with manual annotations" at the end of this Section~\ref{ssec:lp_relationship_small_variations_qual}
\end{enumerate}

Figure~\ref{fig:raw_clique_data} shows an example drawn from our dataset. We can see how the same detail has been phrased differently by different news articles.
The last sentence was removed because it was $100\%$ similar to the third one, and we only accept similarities in the range $[80\%,98\%]$.

\begin{figure}[!htbp]
    \centering
    \fbox{\includegraphics[width=\linewidth]{figures/annotation_212_raw_with_duplicate.png}}
    \caption{Example of a cluster of sentences that we used to build sentence pairs.}
    \label{fig:raw_clique_data}
\end{figure}






\section{Different Techniques of Persuasion}
\label{sec:lp_techniques}

% TODO preamble to different techniques: sentiment, propaganda, populism, ...

From all the different methods and approaches described in Chapter~\ref{sec:lit_propaganda}, in this section, we are using a set of methods to detect phenomena related to persuasion. % and do that at the word-level.
In other words, we are detecting several techniques that are considered
%\todoHA{Assume? No references to support this assumption} 
to be related to persuasion~\citep{gass2018persuasion}: sentiment and 18 different propaganda techniques.% and populism.
%\todoAW{I imagine that there's probably quite a lot of linguistics literature in this area that you should look at, if only to pin down your terminology. → easier to work out the terminology. At the moment I have persuasion (as top) then prop/sentiment/ that are subclasses. Look in literature.}


When selecting which techniques to target, we have an important requirement to keep in mind: we are interested to work at the word-level, because our end goal is to study how persuasion techniques relate to the variations across the articles (as will be seen in Section~\ref{sec:lp_relationship}). Only having a score for the whole article or for a whole sentence is insufficient, because we need also word-level information.

\begin{figure}[!htbp]
    \centering
    \fbox{\includegraphics[width=\linewidth]{figures/updated_annotation_212_sentiment_cropped.pdf}}
    \caption{Sentence-level and word-level sentiment detection on a sentence pair.}
    \label{fig:example_sentiment}
\end{figure}

For example, let us consider Figure~\ref{fig:example_sentiment}.
The words with a coloured background are detected to carry sentiment, while the score at the end of the sentence represents the output sentiment of the whole sentence.
If we only consider the output scores at the sentence level, we just have the result that the first sentence is more negative than the second one. With only a single overall score, it is difficult to compare the single words that are responsible for the scores.
% \todoAW{You really need an example here. I don't understand why you think that a sentence-level analysis is not helpful, nor why a word-level analysis would help.}
%\todoAW{Not sure what you're getting at here. What information exactly are you hoping for at the word level? And it's not usually single words that persuade; rather, it's usually a sentence or article. So it's fine to want to identify the properties of the words that make them propagandistic, but I'd be wary of suggesting that that means you shouldn't be trying to also do a sentence- or article-level analysis.}
With the word-level scores instead, we can see the single terms responsible for the score, and compare them with what changes between the sentences (analysis from the previous chapter).
However, having a score on the sentence-level is useful to capture complex cases where no specific word is responsible but it is the context that makes a subset of words responsible for the persuasion techniques of the text (e.g. when using \texttt{Doubt} or \texttt{Repetition}).
Therefore, we need both word-level and sentence-level outputs from the analysis.
%We need to have in output the responsible words from the analysis tools, because we want to see how persuasion differs when very similar sentences exist. We can already compute which words differ, and we want to see if these words are also expressing persuasion.
% \todoAW{You've attempted a justification here, but it's very wordy and I can't follow it. An example would clarify things much more.}

In the following subsections, we illustrate the models that we are using to perform sentiment detection (Subsection~\ref{ssec:lp_techniques_sentiment}) and fine-grained propaganda detection (Subsection~\ref{ssec:lp_techniques_propaganda}).

% Then in Subsection~\ref{ssec:lp_techniques_populism_vs_propaganda} we show some work done on populism. Even though we don't have computational detection of populism, we wanted to see the relationship that it has with propaganda.\todoAW{Not sure this para is necessary}

\subsection{\statusorange Sentiment Detection}
\label{ssec:lp_techniques_sentiment}

First of all, we start with sentiment detection.
As we have seen in Chapter~\ref{chap:literature}, persuasion is very often related to an emotional response from the reader, being related to emotions~\citep{rocklage2018persuasion,petty2015emotion,desteno2004discrete} and to sentiment~\citep{gatti2014sentiment}.
% While computational approaches to detect emotions exist (usually quantified across the 5-big emotions),\todoAW{Which are? Reference? (x-ref, if you've discussed elsewhere)} the computational tools available for sentiment detection are more numerous and more common.\todoAW{than what?}
% The main difference of only using sentiment detection instead of emotions\todoAW{I don't know what difference you're trying to draw between sentiment and emotion.} is that it usually gives an output on 1 or 2 axes:\todoHA{this not a good enough reason to ditch emotion analysis altogether. 
% might be best to only talk about sentiment here, and leave the mention of emotions to the end of the chapter in the discussions section, and again in the Discussions chapter for the whole thesis.} %\todoAW{Wouldn't a 2-dimensional analysis be more fine grained than a 5-bucket "big emotion" analysis? In which case, it's an advantage of using sentiment rather than emotions.}
% valence (positive or negative) and strength (from neutral to strong). %But for an initial analysis, we deem\todoAW{How?} that sentiment is enough.
We have seen that sentiment detection gives outputs over two different axes: polarity (positive or negative) and strength (from neutral to strong).

For the reasons introduced above, we focus here on term-based analyses that
% For detecting the sentiment, we decide to use term-based analyses. % that, despite being less accurate than huge deep-learning models, \todoAW{How much less? If they're doing different tasks (word-based v. document based), how can their relative accuracy be measured?}
%\todoHA{in comparison to what?}
can provide the specific words responsible for the output.
Our main focus is to see which words are responsible for the sentiment scores, %, instead of optimizing for accuracy.\todoHA{best not to bring up accuracy at all here. not at this stage. you don’t want to tell the reader up front that your approach is not accurate enough. }
% Our main reason is to be able 
to find words that are loaded with sentiment. %If the score of sentiment is not perfect, it is not a problem.\todoHA{unclear} \todoHAinline{You are telling the reader that accuracy will be bad, and that this is ok. But unclear why it will be bad, and why this is ok. Better to leave accuracy to much later, rather that accepting low accuracy upfront}

In the next paragraphs, first we describe the chosen detection tools, then we describe how we combined them together and what they are able to extract on the considered datasets. Finally, we conclude with some findings that we discovered while applying sentiment detection to news articles. % (big variations of sentiment across the articles, correlation with quotation).
%\todoAW{If you're using OTS sentiment analysers, you don't really need to justify their lack of accuracy. Rather, you should focus on what it means for your own results, and whether the (lack of) performance of the sentiment analyser will excessively impact your work.}

\subsubsection{\statusgreen Sentiment Analysis Tools}

Being our main goal to get the words responsible for sentiment scores, we primarily focus on lexicon-based methods.
% For detection, most of the methods that we pick are lexicon-based. This happens because of our focus on getting the words responsible for the scores.
% \todoHAinline{change the order. start by explaining your needs, and justify them, then explain what you found/selected}
% Most of these tools work based on a lexicon that is combined with different scoring mechanisms (e.g., sentistrength, textblob, vader).
They are built around a lexicon where each word has a specific score, and some combination rules.
However, we do not exclude tools that work with a different, more complex approach. It is only required from them to give a score specific to the individual words. For example we also selected Stanford CoreNLP which is based on a RNN~\citep{socher2013recursive}.
%that accounts for the sequence but also for the dependency tree of the sentence.
%(in other words, discovering the combination rules autonomously).
It is not based on a lexicon, but instead on a more complex dataset linking sentiment scores to a dependency tree.
% We selected the following methods: sentistrength, textblob, vader, Stanford CoreNLP

% how we extract the word scores from lexicon
Some of the tools that we use (e.g., TextBlob described below) natively provide methods to get a list of terms that are loaded with sentiment.
Some other tools (e.g., Sentistrength, Vader below) instead only provide the total score on the sentence/document level.
However, having the lexicon provided together with the tools, we can obtain the word-level information by matching the lexicons (that provide the words + scores) with the analysed sentence.

The method to align the lexicon with the sentence is the following:
\begin{enumerate}
    \item the lexicon is loaded: the lexicon provides words (with sometimes jolly operators ``\texttt{*}" and ``\texttt{?}" to match with more than a single word) and sentiment scores;
    \item the sentence is segmented into words;
    \item the sentence words are matched with the lexicon words;
    \item the sentence words are attributed with the lexicon scores.
\end{enumerate}

% Describe each of the methods
Here we describe each of the methods used.

\paragraph{Sentistrength}
The first tool considered is Sentistrength,\footnote{\url{http://sentistrength.wlv.ac.uk/}} built around a lexicon of 2546 words (or in some cases \emph{word stems}) where each entry is annotated with a score (integer in the range $[-5;5]$) and a set of combination rules considering negations, boosters, questions.
% \todoAW{Examples?}
Figure~\ref{fig:sentistrength_example} shows an example of these sets.

% figure from https://www.researchgate.net/publication/273339197_A_Framework_for_Sentiment_Analysis_in_Persian/figures?lo=1
\begin{figure}[!htbp]
    \centering
    \includegraphics[width=0.5\linewidth]{figures/sentistrength_example.jpg}
    \caption{Sample words from the lexicon of Sentistrength.}
    \label{fig:sentistrength_example}
\end{figure}

The outputs given can be retrieved in different forms:
\begin{itemize}
    \item Dual score: as the name suggests, it gives two values, one for the Negative score ( -1 not negative to -5 extremely negative) and a Positive score (1 not positive to 5 extremely positive). A sentence can be both positive and negative so the two scores are independent
    \item Binary $\set{positive, negative}$
    \item ternary $\set{positive, neutral, negative}$
    \item Scale: integer value in $[-4;4]$,
\end{itemize}

However, as we said, we are interested in the single words responsible for the sores, so we use the method explained above to align the analysed sentence with the lexicon of this tool.
% to adapt the tool to output them. We achieve this by comparing the sentences with the lexicon and outputting the original scores given to them.
% \todoAW{Do we get more detail on this anywhere? Need a x-ref.}

\paragraph{Vader}
Very similarly to Sentistrength, also Vader\footnote{\url{https://github.com/cjhutto/vaderSentiment}} has a lexicon-based approach and does not natively give in the outputs the words responsible for the sentiment. Vader has been built mostly to analyse social media content, optimised for short texts.
Its lexicon is composed of 7520 words, and each entry has the raw annotations (10 annotations with integer value in $[-3;3]$) and the mean score + standard deviation.
The outputs can be read in two modalities:
\begin{enumerate}
    \item compound: where each analysed text gets assigned a single value (float) in the interval $[-1;1]$ (-1.0 negative 0 neutral 1.0 positive);
    \item separate scores: Positive, negative and neutral scores which sum to $1.0$.
\end{enumerate}

Also for Vader, to obtain the single words that are loaded with sentiment, we use the method described above to align with the lexicon.
% The advantage of this tool is that the lexicon is much larger than the one from Sentistrength.
% \todoAW{Risky comment: you can modify sentistrength with your own lexicon and then retrain it. This is pretty well established, so I don't think you can really count this as an advantage unless you can convicingly argue that you've a good reason for only considering the prebuilt models.}
% \todoAW{Did you address my earlier comment on lexicon size?}



\paragraph{TextBlob}
The next tool is TextBlob,\footnote{\url{ https://textblob.readthedocs.io/}} which instead provides already the words/parts responsible for the sentiment, whithout the need to look at the lexicon separately.
The lexicon only contains adjectives and adverbs, in total 2918. Each one of them is marked with the \emph{polarity}, \emph{subjectivity}, \emph{intensity} (for the booster words / adverbs) %\todoAW{What's a booster word? "very", for example? If so, that's an adverb, not an adjective.} 
and with the \emph{confidence}. Having these scores, the tool keeps track of the input text across two dimensions: polarity and subjectivity.
Therefore, the outputs of the analysis are the two scores of \emph{polarity}, a real value in $[-1;1]$ (-1 negative, 0 neutral, 1 positive), and \emph{subjectivity}, a real value in $[0;1]$ (0 objective, 1 subjective).

It has a relatively small lexicon, but it has the advantage of being focused on the adjectives and adverbs.
Therefore, if used in combination with other tools, it will provide more adjectives and adverbs, while the other tools will provide more nouns and verbs.
%\todoAW{Why is that an advantage? If I describe someone as a "bearded idiot" for example, then I'm intending the noun to be the main sentiment bearer rather than the adjective.}


\paragraph{Stanford CoreNLP}
Finally we consider Stanford CoreNLP, which is a tool that performs several NLP tasks, and one of them is sentiment analysis.
Differently from the previous tools presented here, this tool is based on a more elaborated approach involving a special RNN which relates to the parse tree.
The dataset used to train this sentiment analysis model is Sentiment Treebank\footnote{\url{https://nlp.stanford.edu/sentiment/treebank.html}} which contains sentiment scores linked to dependency trees.

The outputs of the sentiment analysis module are dual. There is an overall score of sentiment to the full sentences. It also generates a SentimentTree which is a representation of how the sentiment is conveyed from the leaves (the single words) to the full sentence, following the dependency tree.
The scores in output (both total and parts of the tree) have an integer value in the interval $[0;4]$ (0 = Strong\_Negative, 1 = Weak\_Negative, 2 = Neutral, 3 = Weak\_Positive, 4 = Strong\_Positive).

% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=\linewidth]{figures/parse_tree.png}
%     \caption{A SentimentTree parsed. We can extract the sentiment scores of each word.}
%     \label{fig:parse_tree_corenlp}
% \end{figure}

\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/sentiment_tree_2.png}
        \caption{SentimentTree generated by CoreNLP.}
        \label{fig:raw_sentiment_tree}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.45\textwidth}
        \centering
        \includegraphics[width=\textwidth]{figures/parse_tree.png}
        \caption{SentimentTree parsed.}
        \label{fig:parsed_sentiment_tree}
    \end{subfigure}
    \caption{Inputs and outputs of the parser for SentimentTree.}
    \label{fig:parsing_sentiment_tree}
\end{figure}

From the SentimentTree, we wrote a parser that parses its syntax and extracts the scores to the single words.\footnote{\url{https://github.com/MartinoMensio/corenlp-sentiment-tree-parser}}
Figure~\ref{fig:parsing_sentiment_tree} shows the input and outputs of this parsing. On the left, the input SentimentTree from CoreNLP. On the right, a visualisation of the parsed tree, which allows to extract the sentiment of each word.
% \todoAW{I don't think we did; writing a parser is a major undertaking.}
In this way, we are able to see the sentiment of the single words and not only the overall score for a sentence.
%\todoAW{Really needs some examples to illustrate this point.}

% \todo{
% 1. Compare outputs of the tools
% 2. Justify combination
% 3. Say how combination
% }

\subsubsection{\statusgreen Statistics over AllSides Dataset}

% How they perform separately on the dataset (justifying why all of them) and the result of combination.
In this subsection we provide some statistics about how the described approach for sentiment detection works on the AllSides dataset.

% average scores
We compare here the scores and the words provided by the different tools listed above.
To compare the values, given that each tool has its own scale, we first normalise all of them to the same interval of $[-1;1]$.
To normalise the scales, we consider two main axes: polarity (used by all of the tools) and strength (provided by SentiStrength, and subjectivity by TextBlob). We map the numerical intervals from the corresponding $[min;max]$ to $[-1;1]$ by means of a linear transformation. The categorical values, instead, are mapped by firstly sorting the output labels from negative to positive, then converting to increasing numerical values (e.g., for 4 labels, $\set{1,2,3,4}$) and then applying the linear transformation as in the other case.

% - Unified scores by each tool (polarity and strength)
% For the output scores, we consider the unified scores discussed previously. 


\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[trim={0 1.5cm 0 2cm},clip,width=\textwidth]{figures/sentiment_polarity_comparison.pdf}
        \caption{Sentiment polarity.}
        \label{fig:sentiment_polarity_comparison}
    \end{subfigure}
    % \hfill
    \begin{subfigure}[b]{\textwidth}
        \centering
        \includegraphics[trim={0 1.5cm 0 2cm},clip,width=\textwidth]{figures/sentiment_strength_comparison.pdf}
        \caption{Sentiment strength.}
        \label{fig:sentiment_strength_comparison}
    \end{subfigure}
    \caption{Sentiment polarity and strength provided by different tools.}
    \label{fig:sentiment_axes_comparison}
\end{figure}

For each article, we produce the outputs using each tool, and we then aggregate over the whole dataset.
Figure~\ref{fig:sentiment_axes_comparison} shows the average values across the two main axes considered (polarity and strength).
The plot shows boxplots that represent the median (line in the middle of the box), first and third quartile (colored box boundaries) for the considered tools (four for polarity, two for strength) and for the arithmetic mean.
We can see that, even being normalised to the same interval, these tools provide different distributions.

% - polarity
Starting from the polarity values, that describe how positive or negative is the sentiment, we have some tools that have values more extreme than others.
Vader, for example, has values that are very spread out.
For example, the values of Vader reach very often the maximum and minimum (first and third quartile).
TextBlob and CoreNLP instead have a much smaller range, but with a different mean. CoreNLP provides generally more negative results, while TextBlob more positive ones.

% - strength
For the sentiment strength instead, we only have two of the four considered tools that provide values.
The distributions show differences across tools, with Sentistrength providing the higher values.


% % - Correlation between tools
% Then we proceeded to study the correlation between the outputs of the different tools.
% The most correlated are ???
% Instead ??? provides results quite unrelated to the others.

\begin{figure}
    \centering
    \includegraphics[trim={0 1.5cm 0 2cm},clip,width=\textwidth]{figures/sentiment_words_comparison.pdf}
    \caption{Percentage of sentiment words provided by different tools.}
    \label{fig:sentiment_words_comparison}
\end{figure}

% Words:
% - percentage of words detected by each tool
For the analysis of the word-level instead, we computed the percentages overall the whole datasets of the words detected by each tool.
Figure~\ref{fig:sentiment_words_comparison} shows the word-based percentage of sentiment. To obtain this value, we count the terms that are detected as carrying sentiment for each article.
For some tools, these are provided natively, while for others we use the lexicon alignment described previously.

We can see from this figure that each tool detects a quite high number of words as related to sentiment ($5-8\%$), and for some outliers we reach values above $50\%$.
% - percentage of words detected by combination

% % - term analysis: most frequent words positive/negative
% We also perform a term analysis to see which words are the most frequent positive/negative. Figure~\ref{TODO} shows that ???

% % Group by News source:
% We also break down the analysis to the individual news sources.
% % - sources with highest/lowest/strongest
% We find that the sources with the most positive sentiment are ??? while the ones with most negative sentiment are ???.
% Instead on the axis of strength, the news sources that have strongest sentiment are ???
% % - most frequent sentiment words for the most frequent sources

% \todo{figure by news source}

Overall, we see that using these tools introduces one main limitation: false positive words. Many times by inspecting the results, we see that words that should not be sentiment-related instead are annotated as such, as also Figure~\ref{fig:sentiment_words_comparison} denotes.
%Also by looking the overall percentages, we can see that they are relatively quite high.
% How am I compensating for it?
We already removed the outputs from some other libraries because they were providing even more wrong results, but this remains a main problem.

% Combined results? Or stop

\subsubsection{\statusgreen Combination of the Tools}

% \todoAWinline{So from the previous section, I don't really get a sense of the practical differences between the approaches, as you haven't given a running example that would let me see what the difference between the systems is. Also, you don't seem to have discussed what scope there is for adjusting the lexicons for each system, or what difference that might make to the final analysis.}
% \todoHAinline{deciding to combine upfront is not very good. Better way is to use them individually, then combine. This way you scientifically demonstrate value of each approach.}
% Why combine
From this list of tools, we decided to combine them together in order to increase the accuracy of the sentiment recognition. %\todoAW{I think you mean that you wanted to improve the accuracy of the sentiment recognition.}
% As each one of them has different
%\todoHA{what if they contradict each others?} 
% lexicons covering different groups of words (e.g., TextBlob only adjectives),
%and given that they do not overlap totally,
% \todoHA{avoid such vague language. This is also not supported by any data. Why not?}
For the sentiment score, we opted to use an arithmetic mean to provide more stable results.
In case of failure of one of the tools, if we consider the average we have a safer score to provide.

Instead, for the word-level detection, we have the problem of too many words being produced by each of the tools.
Therefore, we decide to use a combination rule that annotates a word when at least two of the tools detect it as carrying sentiment.
In this way, we reduce the amount of false positives.
% As each tool provides different words in output
% the combined lexicon (not correct word, because CoreNLP does not use one) / detection power can be much larger than just considering one of them.
% \todoAW{proof?}

% How combined all of them
We therefore combine the tools in the following way:
\begin{enumerate}
    \item running the tools in parallel;
    \item collecting the results;
    \item numerical scores: uniforming the scales (each tool has a different one) and averaging the single scores out;
    \item sentiment words: doing the union of the words that are recognised by at least two tools, and for each word we compute the average score (again by uniforming the values first).
\end{enumerate}
% we run them in parallel for each input text, and then we collect the results.
% We consider two types of outputs: the score(s) given to the text, and the words responsible for the score.

% For the score, uniforming the scales and doing the average. Ranges --> conversion --> average

% For the words, we take the union of the words outputted from each tool. Each word can then have a positive/negative score so we also merge them,.
% If one word is given back by just one tool, then the score is given by the tool (uniforming again the score as above). Instead if the word is given back by multiple tools, we consider it only once and we average the uniformed scores.

Even if we average and combine the results, we keep the original outputs for each tool in order to backtrack the results and see where the problems come from.


% \todoAW{Would it have made more sense to combine the lexicons from the different systems and then used them to augment one of the existing models (eg. SentiStrength)? Even if not, you should be prepared to answer that question in your viva.}


% \subsubsection{\statusorange Sentiment variation along articles}

% \todomargin{MM: Maybe this subsection is not important, and drifts away from the main focus of this chapter}

% With this setup of the tools, we moved to inspect the articles more closely. We want to see how the sentiment changes from the beginning to the end of the articles.\todoHA{why? what is the value of knowing this?} %and if it is linked to any other external factors.\todoHA{like what?}\todoAW{Such as the reader? Very vague!}
% % We then experimented with the selected libraries to see how they could analyse the sentences in news articles. 
% We started by observing how the sentiment scores vary across one article at a time, when we consider the sentences of the articles.\todoAW{Earlier, you were arguing that you were concerned about word-level sentiment rather than the sentence or article level}
% For each sentence, we compute the sentiment scores and then we compare how the tone varies across a single article at a time.\todoHA{changes how? and what change would tell us? remember that reader won't know why you are doing something unless you make that clear}
% For example, fluctuating between subjective and objective tones.

% Figure~\ref{fig:sentiment_across_one_article} shows how the detected sentiment changes a lot across an article.
% \todo{which article is it? Why this one?}
% Some sentences appear to be very neutral, and some instead are very subjective/intense. And we want to understand why and if this is only a glitch of the sentiment detection libraries.

% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=\linewidth]{figures/sentiment_across_article.png}
%     \caption{Sentiment along a single article. Each point on the x axis is a different sentence, while vertically on the y axis several scores are plotted.}
%     \label{fig:sentiment_across_one_article}
% \end{figure}
% \todoAW{I don't understand this. Why aren't the axes labelled? What does the title mean? And where is the graph described and interpreted in the text?}
% \todo{Fig~\ref{fig:sentiment_across_one_article} coming from which libraries?}

% % \subsubsection{Sentiment is correlated to quotation}
% By looking closely at several articles where this oscillation occurs, we noticed that this duality of tones\todoHA{clarity} in the articles is mostly correlated to direct/indirect reporting. 
% Our hypothesis is that when the articles give space to some interviewee (quoted)\todoHA{shouldn't this be part of the evaluation? why mentioned here?} the sentiment libraries detects intense and subjective words/scores. Instead, when the reporter is narrating, the tone is quieter and more neutral.
% \todoHAinline{you need examples throughout}

% To study this correlation on large scale on our dataset, we tested our hypothesis by considering on one side the sentiment libraries, and on the other side a model for quotation detection~\citep{scheible2016model}.\footnote{\url{https://github.com/christianscheible/qsample}}

% For each sentence, we computed both sentiment score and the quotation percentage (defined as number of words inside a quotation divided by total number of words).
% Figure~\ref{fig:sentiment_vs_quotation} shows for the same example article, how the two measures are moving together.

% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=\linewidth]{figures/sentiment_vs_quotation.png}
%     \caption{Sentiment VS quotation}
%     \label{fig:sentiment_vs_quotation}
% \end{figure}
% \todoHA{This is too crude. Think of a more precise way of measuring such correlations}

% \todo{Compute correlation across all the dataset. Quantify. Then support with some figures}

% Findings of this experiment

% Finding 1:
% Subjectivity and quotations: quotations increase subjectivity of articles, are the most subjective parts

% Finding 2 (shown in previous subsection): the results of lexicon-based sentiment detection are not very great, and they are prone to many errors.


% The conclusion is that when we consider the output scores of the sentiment analysis of sentences, the results may have a bias whether they are analysing a sentence with quotation, showing higher subjectivity and more sentiment, with respect to sentences without quotations.

\subsection{\statusgreen Fine-grained Propaganda Analysis}
\label{ssec:lp_techniques_propaganda}

As a second group of persuasion techniques, we consider \gls{propaganda}.

As we have seen in Chapter~\ref{chap:literature}, propaganda is a form of persuasion that is characterised by its goal to indoctrinate population towards an individual or a particular agenda~\citep{bernays}.
It manifests through several techniques that have been studied in the literature~\citep{torok2015symbiotic}. Each technique has its own peculiarities.

For detecting propaganda, we want an approach that gives us not only a binary label (propaganda vs non-propaganda), but we want to have an insight about which specific techniques have been used.
Knowing which techniques have been used helps us to have a more distinctive persuasion profile of the articles analysed.

Our main goal in this chapter is to describe the differences between multiple versions of the same detail, and if we have more dimensions, it is better.
For this reason, we need to have fine-grained detection of propaganda, that produces as output the specific techniques used and which words are responsible for it.
Taking from the literature described in~\ref{sec:lit_propaganda}, we consider the recent work of~\citet{da2019fine} as it is able to provide fine-grained detection. This method uses a neural network to annotate text articles and to see which words belong to specific propaganda techniques (Figure~\ref{fig:propaganda_example_1}).
The model is a sequence model based on BERT. It is based on the PTC dataset that is part of the same paper. This dataset contains articles annotated at the span level (specific words are highlighted and assigned to a specific technique). The model then learns to reproduce these annotations by looking at words in their context (sequence model).

The classification is performed on the word level, additionally using the left and right context of the text. Each word is classified as being one of 18 different techniques or none of them.
We use this detection algorithm off the shelf,\footnote{\url{https://github.com/qcri/PropagandaTechniquesAnalysisBERT}} only wrapping the code in a client-friendly environment to simplify the integration in our processing pipeline.\footnote{\url{https://github.com/MartinoMensio/PropagandaTechniquesAnalysisBERT}}


\subsubsection{\statusgreen Statistics over AllSides Dataset}
\label{ssec:lp_techniques_propaganda_stats}

We present here an analysis of how this model works on the dataset that we used mostly in this chapter.
% The dataset chosen for this are AllSides and All-the-News
The dataset, presented in Section~\ref{sec:lp_datasets}, is AllSides.

The processing pipeline that we use consists of the following steps:

\begin{enumerate}
    \item Load the text of the articles from the dataset.
    \item Use the model for fine-grained analysis of propaganda techniques: this produces a set of annotated spans in the document, highlighting the words that are detected as containing one of the propaganda techniques, together with the labels of the techniques.
    \item Compute word-level percentages of each technique for each article: we define this metric as the total number of words belonging to each technique divided by the total number of words in the article.
    \item Accumulate the frequencies of each word that is detected as containing any propaganda technique.
    \item Compute the TF-IDF of the propaganda terms counted in the previous step.
\end{enumerate}


% Stats: 
% define metrics for quantities: definition of word-based percentage, overall word-based percentage of propaganda (any techniques), technique specific percentages.
% Then present metric values for quantities.

Across the dataset, we have that on average, $5\%$ of the words are detected as being part of any of the 18 propaganda techniques considered.
The standard deviation is $4\%$, and the maximum value of $56\%$ is caused by an article that is just two sentences long. Except a few outliers caused by partial articles or errors in the scraping, the values are in an acceptable range, as the standard deviation confirms.
% https://www.nytimes.com/2019/08/06/books/toni-morrison-dead.html

% Overall word-based percentage of propaganda
% count    36274.000000
% mean         0.054099
% std          0.041590
% min          0.000000
% 25%          0.023761
% 50%          0.044807
% 75%          0.074553
% max          0.566957

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/prop_tech_detail_baly.pdf}
    \caption{Word-based percentage of propaganda techniques in the AllSides dataset.}
    \label{fig:prop_tech_detail_baly}
\end{figure}

We then break down the statistics to the single techniques, and we can see in Figure~\ref{fig:prop_tech_detail_baly} that several techniques are detected across the dataset.
the most frequent one is \texttt{Loaded\_Language}, which appears on $1.6\%$ of the words.
Successively, we also have other techniques that appear quite frequently (close to $1\%$, such as \texttt{Doubt}, \texttt{Flag-Waving}, \texttt{Name\_Calling}/\texttt{Labeling}. Some techniques instead are hardly ever detected, such as \texttt{Bandwagon}, \texttt{Obfuscation}, \texttt{Red\_Herring} and \texttt{Straw\_Men}.


% Term analysis define: most frequent across techniques, technique-specific terms
% Term analysis values.


% % criticism
% From its publication paper~\citep{da2019fine}, we can see in table 6 and 7 that this model has been evaluated in two ways:\todoAW{Did you attempt to reproduce this evaluation?}

% \begin{itemize}
%     \item sentence-level: binary classification, whether the sentence contains propaganda or not. For this task the reported F1 is around $60\%$\todoHA{reported dataset? clarify}
%     \item span-level (full task): whether the corrects words\todoHA{?} have been identified with the correct technique or not, so accounting both for position/boundaries and for the label. For this task the reported F1 is slightly above $22.5\%$
% \end{itemize}

% These statistics make us aware that, even though this model is the currrent State of the Art, its ability to recognise the proper techniques of propaganda are quite low overall.
% Therefore we need to take with a grain of salt the outputs coming from this model.\todoAW{Too informal. What does "tak[ing something] with a grain of salt" mean in practical terms?}

% \todoHAinline{leave self-criticism to later. also, reported \% here are only indicators since other data is different to yours}



% \subsection{\statusorange Propaganda vs Populism}
% \label{ssec:lp_techniques_populism_vs_propaganda}

% \todomargin{MM: maybe move to an appendix? Not really linked to the rest of the thesis}

% % from "Propaganda datasets unbalanced?"
% % What
% In this section, we experiment with another concept from the literature that is shown to be close to persuasion and propaganda: \gls{populism}~\citep{tumber2021routledge,pasquino2008populism}.\todoHA{Not mentioned in intro. Why not?}
% We want to understand: what is the substantial difference between populism and propaganda? Can these two phenomena be related?
% This question arises purely from a logistical point of view: we have automated methods for detecting propaganda, but we do not have tools to detect populism. Therefore, if we can prove that populism and propaganda are actually correlated, then it becomes not important for us to be able to detect something that is very much correlated to something else that we already detect.

% % concepts
% On the conceptual level, propaganda and populism are two separate concepts. The first describes more the persuasion mean used to push for an agenda, while the second one is usually used more together with the actor that wants to push the agenda. Populism is ``a type of politics that claims to represent the opinions and wishes of ordinary people".\footnote{\url{https://www.oxfordlearnersdictionaries.com/definition/english/populism}}
% And to be on the side of ordinary people, it uses propaganda as a mean. So a populistic \emph{actor} uses propaganda \emph{techniques}. Conceptually, they are related.

% \todoHAinline{ok, but what would detecting populism give you? Why is this of value?}

% \todoHAinline{I would start by: 1. explaining value of detecting populism. 2. detecting it and evaluating that, then 3. see if correlated with propaganda}

% % practically/computationally
% On the computational/detection side, we want to see if this relationship between populism and propaganda stands.
% So to evaluate it, we have computational approaches for propaganda detection, but not for populism detection.
% A solution to this problem, is to use a dataset where we have the ground truth for the populism, which will be run through the propaganda detection pipeline. Then we will compute the correlation between the two, and we can establish whether this relationship is proven. The advantage of using directly the ground truth for one of the two phenomena (populism) is that we can only have errors for the propaganda detection.\todoHA{unclear} Instead, if we were to compare two predictions, the errors could be on both sides.

% % dataset used
% For this experiment, after looking at the available datasets for populism, we selected the one from~\citet{hawkins2019global} because it is quite balanced in terms of the political orientation of the actors annotated (liberal vs conservative).\todoAW{It strikes me here that this is a very US-centric interpretation of the political landscape. Do you consider whether the make up of the dataset poses any threats to validity?}
% It contains 1240 political speeches, from several countries and languages
% For each one of them there are four annotators that give a numerical score of populism in the range $[0;2]$ where $0$ means non-populistic and $2$ means very populistic. The single annotations are already averaged out.
% So from the 4961 raw rows, by deduplicating (4 annotations for each speech) we have 1240 speeches, out of which 265 are in English (then down in the rankings, 304 in Spanish and 148 in Portuguese).

% % These 265 speeches all have a leaning classification (we will see more about leanings in the next chapter): 36 left, 37 center, 84 right, 106 NA. We use this information in order to check whether the results that we get are general across the political spectrum.
% % --> moved to chapter 5


% % Dataset found: populism in political speeches %https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/LFTQEZ&version=2.0 
% % Each annotator (4 for each speech) gave a score between 0 (non-populistic) to 2 (very populistic)
% % 4961 rows 
% % 1240 deduped (352 left, 256 center, 469 right, 652 NA)
% % Languages: 265 en (304 es, 148 pt, …),
% % Leaning of the english ones: (36 left, 37 center, 84 right, 106 NA)



% % Goals:
% With this dataset, as we described, we want to compute the 
% correlation between propaganda and populism. So we take each speech in the corpus and we proceed to compute the Spearman's correlation~\citep{spearman1910correlation} between the  populism averaged out between the annotators and different propaganda metrics: total word-based percentage of propaganda, and word-based percentage of each of the propaganda techniques. 


% % results
% The Spearman's correlation between the populism and the total word-based percentage (all techniques together) is $0.1694$. This value is quite low. So it seems that they are quite unrelated.\todoAW{This feels to me like the sort of investigation and analysis which forms the bedrock of your research. So I think you need to set it out more formally so that it feels like less of an aside.}

% \begin{figure}[!htbp]
%     \centering
%     \includegraphics[width=\linewidth]{figures/populism_propaganda_correlation.pdf}
%     \caption{Spearman's correlation between populism and each propaganda technique}
%     \label{fig:populism_propaganda_correlation}
% \end{figure}

% By breaking it down to the correlation of populism to each propaganda technique, we can see in Figure~\ref{fig:populism_propaganda_correlation} that the strongest correlation is found with \texttt{Flag-waving}, \texttt{Name\_Calling/Labeling} and \texttt{Slogans}. Some of the techniques have very low correlation. It is interesting to notice that two techniques have slightly negative correlation (\texttt{Repetition} and \texttt{Appeal\_to\_Authority}), so this means that they are used by less populistic speeches.


% % L/R evaluation:
% % Assumption: propaganda correlates to populism similarly in L/C/R
% % Result total: 0.225 Left, 0.005 Center, 0.374 Right → Why? Is it a matter of quantity of populism/propaganda?
% % Populism average:  [0.1259, 0.0729, 0.2712]
% % Propaganda average: [0.0165, 0.0271, 0.0432]
% % Ratio: [0.1317, 0.3717, 0.1593] → populism over propaganda ratio is a bit bigger on the right (21\% more), but the correlation Right is bigger than the left at 66\%. So it is less likely that this is just a matter of quantity. On the Right, propaganda and populism are strongly linked

% % findings
% Propaganda and populism are correlated, but not too strongly.\todoAW{?}
% The fact that some of the techniques are correlated to populism is a good sign,\todoHA{why?} even though the correlation scores are still low to be considered as ``strong correlation''. We will expand this experiment in the next Chapter when we take into consideration political leaning.
% Considering that the current fine-grained propaganda detection is not so accurate (cf. Section~\ref{ssec:lp_techniques_propaganda}), we can say that this weak correlation can still be considered as a signal that the two phenomena are related.
% % In the Right more. This is one point supporting the hypothesis that propaganda detection works better in the Right than in the Left. → unbalanced detection caused by unbalanced data



\section{\statusgreen Persuasion Techniques vs Variations}
\label{sec:lp_relationship}

After having described in the previous sections the detection of the \emph{linguistic techniques of persuasion} on their own, we describe in this section the combination with the analysis of the variations.
%\todoHA{why combine? what are you hoping to find or learn? always make your thoughts and rationale very clear upfront }
Our motivation is that we want to quantify with persuasion indicators what changes between related articles.
% , from the difference analysis of the previous chapter (from a group of related articles, analyse the differences in terms of omissions, corroborations, fine-grained term differences), 
In the previous chapter, we described a methodology to analyse the differences (omissions, corroborations, fine-grained term analysis) from a group of related articles.
Now that we have here described how we can quantify persuasion with several detection techniques (sentiment and propaganda), we want to combine the two analyses together.

In other words, we want to analyse the relationship between the linguistic techniques of persuasion, and the variations across the articles (from previous Chapter~\ref{chap:common_ground_search}).

To analyse this relationship, we have two different experiments:

\begin{enumerate}
    \item Small variations vs detected persuasion: we want to investigate if the small variations (between several texts about the same detail) do also create differences on the persuasion detected, or if the terms that change are not related to persuasion. This is analysed in Subsection~\ref{ssec:lp_relationship_small_variations}.
    \item Removing persuasion to see the effects on document clustering: what is the effect of persuasion when we want to cluster news articles? We want to test what happens when we remove persuasive words from the articles. Does this improve or worsen the clustering abilities? This is analysed in Subsection~\ref{ssec:lp_relationship_removing}. %\todoHA{why assuming it might be noise?}
\end{enumerate}

\subsection{\statusgreen The Effects of Small Variations on Detected Persuasion}
\label{ssec:lp_relationship_small_variations}

%\todoAWinline{It all starts getting very choppy from here. In general, I think the main thing in this chapter is that your experiments need to be presented more formally. You have interesting looking results, but I don't really see where they come from.
%Ask yourself how someone would reproduce the work you've presented here. I wouldn't know how to start.}


% Why
% What
For this experiment, we want to observe how the small changes detected in the previous chapter affect the detected persuasion.
% Having computing methods for sentiment and for fine-grained propaganda detection, we decide not proceed with populism detection,\todoHA{probably move section on populism to the end since it is weak and experiment not thorough}\todoAW{I'm not entirely clear what that decision was based on.} but only keeping as axes for measurements the sentiment ones (strength and polarity) and the 18 propaganda techniques.

% RQ3
Our \acrshort{rq}2.3 is: \emph{How do similar news articles differ in their use of persuasion techniques?}
So to answer this question, here we take
%groups of linked sentences (from Chapter~\ref{chap:common_ground_search}) and we see how their variations are related to changes in persuasion.
the \emph{Small Variations Dataset} that we introduced in Section~\ref{sec:lp_datasets}.
We annotate the sentences from this dataset with the persuasion techniques just described in Section~\ref{sec:lp_techniques} and then we analyse the relationships between variations and detected persuasion.

One of the main limitations of Chapter~\ref{chap:common_ground_search} was that it was difficult to tell what the changes could convey to the reader. What does selecting one word or a synonym imply? Now with the tools of persuasion detection, we are able to explore this question.




\subsubsection{Approach}
\label{ssec:lp_relationship_small_variations_appr}

Having as goal to understand the relationship between small differences
%in multiple versions of the same detail 
and the use of persuasion techniques, in this experiment we combine two analyses:
\begin{enumerate}
    \item Fine-grained differences analysis from the previous Chapter~\ref{sec:cgs_clustering_and_differences}. We take from this analysis both the link between similar sentences and the indication of how many and which words have been changed and which one are kept the same.
    \item Persuasion analysis seen in the previous Section~\ref{sec:lp_techniques}: we extract sentiment and propaganda techniques from the sentences. This analysis provides scores and the specific words affected.
\end{enumerate}

The point of contact between these two analyses, is to see how the differences relate to persuasion. In other words, see how frequently a change in the wording is related to persuasion, which persuasion techniques change mostly between these sentence pairs, and which specific words are responsible for this relationship between differences and persuasion.

% How: method
We describe persuasion with the help of sentiment detection (as seen in section~\ref{ssec:lp_techniques_sentiment}) and fine-grained propaganda detection (section~\ref{ssec:lp_techniques_propaganda}).
The comparison is done in different ways:
\begin{enumerate}
    \item score: sentiment or propaganda scores. For example, one change in an adjective could result in more negative sentiment, or in more of a specific propaganda technique;
    \item words: the words changed could be the words that carry sentiment/propaganda. Instead of just hypothesising that the change in the words are responsible for a different score (as in the point above), we have a direct indication that the words belong to a persuasion technique.
\end{enumerate}

\begin{figure}[!htbp]
    \centering
    \fbox{\includegraphics[width=\linewidth]{figures/annotation_212_annotated.png}}
    \caption{Pair of sentences annotated by the uniqueness and persuasion analysis.}
    \label{fig:annotated_clique_data}
\end{figure}
% \todoAW{I've missed something, I think... where do you discuss how the detected technique is classified?}
% the answer is in sec:

Figure~\ref{fig:annotated_clique_data} shows a pair of sentences that contain one persuasion technique.
In green we highlighted the words that are unique for the analysed sentence with respect to the other, using the method from the previous chapter.
In purple instead we can see that a specific propaganda technique (\texttt{Apppeal\_to\_fear-prejudice}) has been detected.
Some words (e.g., ``deadly", ``spiral out of control") are both unique to the first sentence and also belong to the technique of \texttt{Apppeal\_to\_fear-prejudice}. Instead in many other pairs of our dataset, the changes do not manifest in terms of persuasion techniques.
Our goal is to understand this relationship between variations and persuasion.

% split between computational results and human judgement
We conduct the analysis following a purely computational approach, meaning that both the detection of variations and persuasion techniques are automated (not coming from a gold standard).
% \begin{enumerate}
%     \item computational-only: we compute how much the differences in wording affect the scores and words of detected persuasion;
%     %\item soft-validation of computational results: we try to see how good the detected changes in persuasion are when we compare to human-generated labels.
% \end{enumerate}
%
% While the first one is less prone to criticism, being computed, the second one is less valid because only I annotated the sentences
% We compute how much the differences in wording affect the scores and words of detected persuasion
We want to measure on average how many variations in percentage also imply a different measured persuasion (in terms of scores). %Are the variations between the texts making the persuasion scores change? 
Furthermore, we also want to analyse if the words changed are also loaded with techniques of persuasion.
% Instead on the validation side with human annotations, we want to check if the results we are getting are 
% \todo{finish sentence}



% Results
% The results have a first quantitative side and then also a qualitative one. ? rename to automated vs manual???
% it depends on which persuasion technique is considered.

\subsubsection{Results}
\label{ssec:lp_relationship_small_variations_quant}

% \todo{compute metrics from results
% Quantitative results\\
% - reduce groups to pairs: select rows and merge\\
% - count statistics about dataset: number of pairs\\
% - find example and create figure with sentence pairs with scores, words\\
% - add propaganda features (score and words) to each csv and merge sentiment analysis (score and words)\\
% - compute score results: score changes average for each technique (shows which techniques are mostly affected by variations)\\
% - compute words results: \#words persuasion / \#words changed\\
% - plot results (techniques vs percentages)
% }
% quantitative
Firstly, we present here some statistics about the \emph{Small Variations Dataset}.
Across the 138 samples included in the dataset, we have on average $32\%$ of the words that are unique. The words that count as unique in a sentence pair are the ones that only belonging to one of the two sentences of the same pair (uniqueness score defined in~\ref{sec:cgs_clustering_and_differences_uniqueness} $u_w = 1$). This corresponds in our example of Figure~\ref{fig:annotated_clique_data} to the words highlighted in green.

\begin{table}[!htbp]
    \centering
    \begin{tabular}{r|rr}
        Technique                             & sentence-based \% & word-based \% \\
        \hline
        any                                   & 89.8\%            & 14.8\%        \\
        sentiment\_total                      & 89.8\%            & 12.5\%        \\
        propaganda\_any                       & 10.1\%            & 3.2\%         \\
        PROPAGANDA:Loaded\_Language           & 4.3\%             & 0.8\%         \\
        PROPAGANDA:Doubt                      & 0.7\%             & 0.5\%         \\
        PROPAGANDA:Flag-Waving                & 1.4\%             & 0.6\%         \\
        PROPAGANDA:Name\_Calling/Labeling     & 1.4\%             & 0.3\%         \\
        PROPAGANDA:Appeal\_to\_fear-prejudice & 1.4\%             & 0.3\%         \\
        PROPAGANDA:Exaggeration/Minimisation  & 1.4\%             & 0.6\%         \\
        PROPAGANDA:Repetition                 & 0.7\%             & 0.1\%         \\
    \end{tabular}
    \caption{Amount of detected persuasion techniques across sentence pairs.}
    \label{tab:detected_persuasion_in_variations}
\end{table}

Considering the persuasion analysis, we first start presenting some high-level statistics of which techniques appear in the dataset.
Table~\ref{tab:detected_persuasion_in_variations} shows the quantities of techniques, considering the sentence-level and the word level. The column \textit{sentence-based \%} represents how many of the sentences have the specific technique detected (it is sufficient that a single word is detected to count the sentence). Instead, the column \textit{word-based \%} represent the word-based percentage of the techniques, counting singularly the words that belong to that technique compared to the total number of words in the dataset.

We can see that in $89\%$
%\todoAW{Don't give accuracy to 1 in 1000 when you've only got 138 cases. 2sf is appropriate here.} 
of the sentences, some techniques are detected.
This is almost always caused by sentiment that gets triggered, while propaganda is detected only in $10\%$ of the sentences.
The average word-based percentage (last column, computed for words singularly) that are detected as related to any persuasion technique is below $15\%$,
%\todoAW{Do you count each of the three words in "out of control"? Does that matter?} 
meaning that even though persuasion appears in approximately 9 out of 10 sentences, usually it appears just in a few words.

Breaking down by type of technique, most of these words are detected as carrying sentiment ($12\%$) while less than $4\%$ relates to propaganda.
We can see that the propaganda percentages are much smaller than the values provided by the sentiment tools.
% \todoAW{Is that because of the content of the documents, or the standard of the technology for recognising them?}
By inspecting the samples, we see that generally sentiment detection finds more terms than the propaganda detection. This means that potentially more words are being recalled, but the precision is much lower because we see lots of false positives, despite the combination approach described in Section~\ref{ssec:lp_techniques_sentiment}.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/4.3.1_propaganda_avg.pdf}
    \caption{Average of propaganda techniques across the dataset of sentence pairs.}
    \label{fig:propaganda_avg}
\end{figure}

Figure~\ref{fig:propaganda_avg} shows the percentages of each detected propaganda technique in the corpus (same values as in Table~\ref{tab:detected_persuasion_in_variations}), but filtering by technique only propaganda and considering the last column.
On the horizontal axis, we find the propaganda techniques that appear in this dataset, while the word-based percentage of the corresponding technique is shown on the vertical axis.
The propaganda techniques appearing the most are \texttt{Loaded\_language}, \texttt{Exaggeration/Minimisation}, \texttt{Flag-Waving} and \texttt{Doubt}.

% number of changes vs score variations
The previous statistics were given on the sentences of the datasets without considering their relationship.
In the next paragraphs instead, we analyse the variations together with the techniques.
How many times the variation of the sentences results in a change over the persuasion scores? How big is the change in the scores?
% We answer these question by considering every minimal change in the scores. And then by considering the magnitude of the change.

\begin{table}[!htbp]
    \centering
    \begin{tabular}{r|rr}
        Technique                             & \% scores changed & avg. magnitude \\
        \hline
        any                                   & 98.5\%            & N/A            \\
        sentiment\_total                      & 98.5\%            & 9.3\%          \\
        propaganda\_any                       & 14.4\%            & 3.4\%          \\
        PROPAGANDA:Loaded\_Language           & 7.2\%             & 1.0\%          \\
        PROPAGANDA:Doubt                      & 1.4\%             & 1.1\%          \\
        PROPAGANDA:Flag-Waving                & 1.4\%             & 0.4\%          \\
        PROPAGANDA:Name\_Calling/Labeling     & 1.4\%             & 0.1\%          \\
        PROPAGANDA:Appeal\_to\_fear-prejudice & 2.8\%             & 0.6\%          \\
        PROPAGANDA:Exaggeration/Minimisation  & 1.4\%             & 0.1\%          \\
        PROPAGANDA:Repetition                 & 1.4\%             & 0.1\%          \\
    \end{tabular}
    \caption{The impact of sentence-pairs variations on detected persuasion.}
    \label{tab:change_scores_persuasion_in_variations}
\end{table}
% \todoAW{Although this (sentence pairs) is presumably working at the sentence level, which you said you didn't want to do?}
% \todoAW{What's that? (percentage of the allowed interval)}

For each pair of sentences, we compute the persuasion scores by technique, as defined previously in Section~\ref{sec:lp_techniques}:
\begin{itemize}
    \item sentiment score: average of the different sentiment tools, each one normalised to the interval $[-1;1]$;
    \item propaganda techniques quantity: defined as the word-based percentage of the considered techniques.
\end{itemize}
Afterwards, we compare the scores of the sentences belonging to the same pair, and we compute the magnitude of the change (if any).
Table~\ref{tab:change_scores_persuasion_in_variations} shows the results of this comparison.
The column \textit{\% scores changed} is computed by considering whether each sentence pair has different scores (any variation counts). The column \textit{avg. magnitude} instead, expresses the magnitude of the change, measured in percentage of the allowed range for each value ($[min;max]$, namely $[-1;1]$ for sentiment score and $[0;100\%]$).
We can see that in $98.5\%$ of the cases there is a change in the scores of at least one technique.
Breaking down this result, we have that in all these cases (still $98.5\%$) there is a change in the sentiment score. The sentiment detection, not only is picking on more terms (with many possible false negatives), but also is very sensible to the terms used (perturbing the output scores).
Propaganda, on the other side, is detected less and is perturbed less.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/4.3.1_normalised_ratio_scores.pdf}
    \caption{Variations of propaganda techniques quantity normalised.}
    \label{fig:normalised_ratio_scores_persuasion}
\end{figure}

We then analyse the ratio between the average magnitude of changes from this table and the average word-based percentages from Table~\ref{tab:detected_persuasion_in_variations} to normalise the results and find the techniques that are mostly affected by this variation.
Figure~\ref{fig:normalised_ratio_scores_persuasion} shows the results of this normalisation.
On the horizontal axis, we have the different techniques that are detected in the corpus, while on the vertical axis the values are computed by dividing the values of Table~\ref{tab:change_scores_persuasion_in_variations} with the values of Table~\ref{tab:detected_persuasion_in_variations}.
%represent how the technique is affected by having the same details provided by two different sentences.
The most affected techniques are \texttt{Doubt}, \texttt{Appeal\_to\_fear-prejudice} and \texttt{Repetition}.
It is important to normalise to discount the effects of the natural disproportion of the techniques used.
For example, loaded language is the propaganda technique most used in general, but as we can see in the figure, it is not the one that changes the most between the pairs of sentences. This could be due to the fact that
%\todoAW{why should that apply more to loaded language than to other techniques?} 
most of the news sources tend to describe with loaded words the same events in their race for attention/clickbaitness~\citep{bazaco2019clickbait,davenport2001attention}.
%\todoAW{OK, good that you've got some citations, but I think I'd include a quote as well to clarify exactly what point these authors are making. }
Therefore, using loaded terms is probably the easiest way to compete and make users read an article. However, techniques that are less evident are the ones in which we can see more differences.


Going back to the sentence pair in the previous Figure~\ref{fig:annotated_clique_data}, only the first one contains \texttt{Appeal\_to\_fear-prejudice} to communicate the detail. This is the type of variation we are interested in.
% Overall, on the quantitative side, we see that a portion (\%?) of the variations in the texts is causing a persuasion score change. Out of X couples of sentences with small variations, only for Y we see a change. Among these, Y1 are changes to the sentiment and Y2 to the propaganda score. The breakdown by techniques is illustrated in the blue bars of Figure~\ref{TODO}, which shows the percentages of variations that correspond to a change in the respective technique. (for each technique, for each sentence pair, a boolean yes/no where yes corresponds to ``changed" and no to ``unchanged", then counting the percentages of yes) 
%
%number of changes vs persuasion-loaded terms: how many terms in percentage?
Therefore, we also compute another measure: how many (percentage) changed words are also persuasion related? Some words can be unique for one sentence but not be related to persuasion, while others can be both unique and loaded of one/more persuasion techniques.

\begin{table}[!htbp]
    \centering
    \begin{tabular}{r|rr}
        Technique                             & \%pairs & \%words \\
        \hline
        any                                   & 86.9\%  & 18.8\%  \\
        sentiment\_total                      & 85.5\%  & 17.0\%  \\
        propaganda\_any                       & 10.1\%  & 2.9\%   \\
        PROPAGANDA:Loaded\_Language           & 5.7\%   & 1.0\%   \\
        PROPAGANDA:Doubt                      & 1.4\%   & 0.4\%   \\
        PROPAGANDA:Flag-Waving                & 1.4\%   & 0.1\%   \\
        PROPAGANDA:Name\_Calling/Labeling     & 0\%     & 0\%     \\
        PROPAGANDA:Appeal\_to\_fear-prejudice & 1.4\%   & 0.7\%   \\
        PROPAGANDA:Exaggeration/Minimisation  & 1.4\%   & 0.6\%   \\
        PROPAGANDA:Repetition                 & 0\%     & 0\%     \\
    \end{tabular}
    \caption{Comparison of persuasion words against unique words.}
    \label{tab:words_persuasion_in_variations}
\end{table}

In Table~\ref{tab:words_persuasion_in_variations} we show the values of this measure.
The column \textit{\%pairs} is defined as the ratio between the number of sentences where at least one word of persuasion is also a unique word (not in common with the other sentence in the pair) and the number of sentence pairs. The column \textit{\%words} instead is defined as the total number of words that are both persuasion and unique, divided by the total number of unique words.
In $86.9\%$ of the pairs, we have words that appear only in one of the two sentences that also contain some persuasion. The proportion word-based is $18.8\%$ as we have 2240 words that have been changed (out of 138 sentence pairs, summing the unique words for each pair), and 422 of them are related to persuasion.
We can confirm the results found when using the scores instead of the words. The only differences are in the \texttt{Name\_Calling} and \texttt{Repetition} techniques, that in this case do not overlap with the unique terms.

% All these results are really useful to understand the relationship between the detected persuasion and the variations appearing in multiple versions of the same detail, we have a main limitation which is: does this analysis reflect on what a news consumer would perceive?
% To try to give an answer to this question, we make use of the following subsection which analyses the correlation with human judgements.

% \subsubsection{Computational vs Human Judgement results}
% \label{ssec:lp_relationship_small_variations_qual}

% For this last part of the experiment, we want to understand whether the findings of the previous computational analysis are possibly indicating something that really exists.
% For this reason, we conducted a very limited analysis based on manual annotations.

% TODO

% \todo{
% Qualitative results:\\
% - annotate a subset of pairs: does this change mean something in terms of persuasion? Boolean\\
% - "confusion matrix"\\
% - plot barchart of the ones that behave mostly as predicted\\
% - limitations: because these annotations are done only by me
% }

% Goals:
% - understand how the previous computational results are not just picking any changes. $98.5\%$ of the variation caused a change in the persuasion scores, so we need to assess if we are not only???? 


% Manual annotation of whether the differences in the sentence pairs are making use of different persuasion or relate to a different opinion / point of view. This specific data is used for the experiments ``comparison with manual annotations" at the end of this Section~\ref{ssec:lp_relationship_small_variations_qual}

% % annotations why how and annotation guidelines
% TODO

% Then the qualitative results: do the scores/words represent correctly the persuasion differences? For measuring this, we rely on manual analysis of a subset of sentence pairs. We selected these pairs randomly. We manually label these pairs (How many?)
% (because we don't actually have the ground truth, we are estimating it based on our observations) in two categories: with differences in persuasion or without them.\todoHA{I'm assuming this text not finished?}

% We can define reference values in the following way:

% \begin{itemize}
%     \item \textbf{reference value}: our estimation, but not really a "ground truth";
%     \item \textbf{detected}: whether a persuasion score changes between the two sentences
% \end{itemize}

% Therefore, the true/false positives/negatives for the confusion matrix become:

% \begin{itemize}
%     \item True positive: our estimation is that it should change, and it actually changes.
%     \item False positive: our estimation is that the sentences carry the same type of persuasion, but the detection of persuasion tells that there is something different
%     \item False negative: we deem that the two sentences should contain a change in persuasion, but the detection says nothing
%     \item True negative: no change should be contained, and detection does not detect differences on the persuasion level.
% \end{itemize}

% % results
% The results show???\todo{finish}

\subsubsection{Findings and limitations}

% findings
All the results are really useful to understand the relationship between the detected persuasion and the variations appearing in multiple versions of the same detail.
% quantitative
We have been able to find which techniques change mostly due to the changes represented in our corpus. Furthermore, we understand how a detail may be rephrased to express persuasion.
Being that some techniques appear more (such as sentiment and \texttt{Loaded\_Language}) and some other less, we normalised the variation of the persuasion scores based on the average quantity of each technique.
By doing that, we discovered that some techniques which are more rare (e.g., \texttt{Doubt}, \texttt{Appeal\_to\_fear-prejudice} and \texttt{Repetition}), are much more probable to occur only in one of the variations of the same detail.
This is particularly meaningful when contextualised to the attention economy~\citep{davenport2001attention}:
%\todoAW{I think you need to flesh this out a bit, although a well selected quote from D\&B should be fine for that.}
the easiest way to capture the attention is to use ``emotional triggers".
Therefore, sentiment and loaded language are the techniques more easy to deploy and we find here that they are more spread to all the versions of the same story.

At the higher level grouping of techniques (sentiment and propaganda, instead of the specific techniques), we found that sentiment detection is providing details that are optimising recall but not precision. We observe that there are many false positives which are disturbing our analysis.
For example, by manually inspecting the samples, we come to the conclusion that not all the changes between the sentences should have resulted in a change of the sentiment score.
This makes it harder to distinguish the cases of word change that really matter. For this reason, sentiment detection might not be the best choice and in the next experiments we decide to use less this feature, in favour of propaganda.

% we have a main limitation which is: does this analysis reflect on what a news consumer would perceive?

% NEED of contextualising the source
One big limitation of our current analysis is that, once we discover how the techniques are related to the variations in the articles, we still do not have a \emph{context} where to place this analysis. We currently lack the information on how to place a news article considering the news source or the author that wrote it.
%\todoHA{unclear. what are you trying to say here?}
For example, propaganda techniques may be used with a political goal or coming from a political standpoint.
We are missing the link between the persuasion used and the original point of view which could motivate such use of techniques.
This limitation will be targeted in the next chapter, considering the perspectives and the political leanings.

Another limitation is that we choose to compute the results using only automated approaches.
To extend this work, we could collect and compare additional manual annotations, to check the validity of the results with human-based judgement (e.g. to validate whether the extracted persuasion is perceived as different in sentence pairs or not).
% However, in the scope of this thesis, we choose to compute the results using only automated approaches.
% \todoHA{this paragraph is odd. It doesn't explain what was your rationale for your choices. Perhaps move it to discussions, or justify your choices more clearly}

% % qualitative
% We then have a set of sentence pairs that only looks like a re-wording with no persuasion changes, and persuasion/propaganda.
% When compared to human juddgement, TODO



% Sentiment

% % sentiment
% Instead for the sentiment analysis, since we want to have detailed information (e.g. which specific words contain sentiment, and with which properties), we are relying on lexicon-based tools. Other more advanced tools (e.g. Stanford CoreNLP) have models which do not provide fine-grained scores but only sentence/document level. (This could be improved)
% % which sentiment lexicons?
% We selected some lexicons: Sentistrength, Vader, and AFINN (TODO description).
% % problems?
% The problem of doing sentiment analysis in this way is that the lexicon is recognised without accounting for other constraints (e.g. POS): we needed to remove some tools because they detected the word "Trump" as being positively loaded (trump as trumpet instead of Donald Trump).


\subsection{\statusgreen Removing Persuasion to Improve Clustering}
\label{ssec:lp_relationship_removing}

The last experiment of this chapter tackles the challenge of analysing the relationship between persuasion and variations in news articles from another perspective.
We approach this analysis from the point of view of clustering.
The previous chapter already analysed the clustering algorithms at the article and sentence level.
Here, instead, we question whether we can help the clustering of articles by removing the persuasion from the articles.

Our \acrshort{rq}2.4 is \emph{To what extent could persuasion techniques be used to identify related news articles?}
%\todoHA{so you are considering that clustering can help recognising events? this is unclear or not well described}}
To answer it, we compare the clustering of the articles when they are complete (not removing anything) against when they have been ``cleaned up" from persuasion.
%\todoHA{Avoid yes/no type of RQs}

% why
The motivation behind this experiment lies in our hypothesis which we described in Chapter~\ref{ssec:lit_layers_of_info}. We hypothesise that news articles are made of two ingredients: topical elements, that are related to events, people, things, and non-topical elements that instead express the opinion of the writer. These two ingredients can be contained in different words or in the same word (cf.~\ref{ssec:lit_layers_of_info}).
In this experiment, by removing the persuasion words, we target both cases but with different effects.
In the case where persuasion words are distinct from topical words, we hypothesise that removing the persuasion words would bring an improvement to the clustering.
Instead, for the case where they appear in the same words, our removal may bring to sentences that are not grammatically complete and may be voided of some topical elements.
%In this experiment, we target only the case where they appear in different words, because it is simpler to separate and see the effect of removal.%\todoAW{But does it invalidate your claims?}
However, we are only considering this simple removal to avoid using more complex models
% For the case where they appear in the same words, we would need to apply some 
(e.g., style-transfer to rewrite the same concepts attenuating/removing persuasion techniques~\citep{bagdasaryan2022spinning}), which is beyond our scope. %\todomargin{ChatGPT citation}
%\todo{if style-transfer is applied, we can also target the cases where they co-live on the same words. check models, there are some for spinning but what about un-spinning?}


% effect of sentiment/propaganda words on sentence clustering
% \todoAW{for doing what? More motivation, this is only operational}

% What: removing the “highlighted” words from the article analysis, the clustering would work better or worse.

% RQ (chap4) 4: Is persuasion an obstacle in recognising the events in multiple articles? (clustering)"

% Why:
% The articles are made of two components:
% the story/event which can be seen from topical words, entities, …
% The layer of framing which here is intended as sentiment-loaded words and propaganda techniques

% Hypothesis
% The framing layer does not help understanding the topics described in the articles. This set of words can be removed to perform clustering better.



% How
To bring this plan into action, we compare the results of  clustering algorithms applied to the full articles against the articles without persuasion terms, to see whether the clustering obtained improves or not.
In the next paragraphs we analyse the dataset used, the approach, the results, and the findings.

% \todo{rephrasing needed for these 3 subsections, at the moment they are quite raw}





\subsubsection{Approach}

Since we want to understand whether by removing persuasion we can have better clustering, our approach is to apply a standard clustering pipeline to two different inputs: first, to the raw articles, and then to the articles with the removed persuasion. So the steps that we do are the following: %\todoAW{This is good... a clear explanation of how you're going to progress.}
\begin{enumerate}
    \item remove persuasion from the article in the first dataset to prepare the second dataset to feed into the pipeline
    \item encode the documents (for both datasets)
    \item run the clustering algorithm (both datasets)
    \item measure the quality of the clusters with the ground truth labels (both datasets)
    \item compare the two cases to determine which one is better
          % \item decide one clustering approach: it needs to be customisable in terms of numbers of clusters
          % \item test the clustering on the articles from the dataset
          % \item measure the accuracy of the clustering with respect to the ground truth
          % \item remove the persuasion terms
          % \item run the clustering on the ``cleaned'' articles, with the same clustering algorithm and parameters
          % \item measure again the predicted clusters with the same metric
          % \item compare the scores and determine which case is better
\end{enumerate}

We carry out this procedure with different number of ground truth clusters, increasing the dataset from an initially small subset.%\todomargin{say this after the description of each step}
The data samples that we use to conduct this experiment is coming from the AllSides dataset presented in Section~\ref{sec:lp_datasets}, as the clusters have a fixed size of 3, which is not as big as the size of clusters of Google News Headlines.

% Test the ability of matching gold clusters with predicted clusters.
% - standard full article
% - removing propaganda/sentiment words

% Seeing if there is an improvement or not when removing propaganda words.

% STEP 1
For the Step 1, we proceed to remove the terms of persuasion with the methods described in Section~\ref{ssec:lp_techniques_sentiment} for sentiment and in Section~\ref{ssec:lp_techniques_propaganda} for propaganda. We input the text articles, and we get in output from the methods the terms that are loaded with sentiment or propaganda techniques. Then we proceed to remove these words from the original articles and we build a second dataset without persuasion terms.
%\todoAWinline{Doesn't this rather assume that the terms can be removed without affecting the meaning? For example, "Johnson heroically took us out of the EU" and "Johnson stupidly took us out of the EU" retain their meaning even if we remove the propagandistic terms "heroically" and "stupidly". OTOH, "Johnson claimed that his actions were legal" and "Johnson proved that his actions were legal" lose their meaning if you remove the loaded terms "claimed" and "proved". Does this matter?}
Additionally, we also have the datasets without only sentiment or propaganda, which come from the original dataset by only removing one of the two persuasion types.
% Removal of the terms: sentiment-loaded terms (multiple lexicons and tools: sentistrength, vader, )
% %And these? AFINN, BING) 
% and propaganda spans (from https://www.tanbih.org/prta).

% STEP 2
For the Step 2, document encoding, we take the approaches
also used in the previous Chapter~\ref{chap:common_ground_search}: we use for comparison both TF-IDF and \acrshort{use}. The first one is selected to represent simpler approaches while the second one stands for more recent and complex ones. The aim of the comparison is to understand whether there is any advantage of using more sophisticated approaches for this task.
While USE is expected to have better results for complete sentences, we are also conscious that using it with possibly incomplete sentences (removing persuasion terms is not guaranteed to build grammatically complete sentences) could bring to slightly worsened results.
% With both models, output for each document is a numerical representation.
% Document representation:
% Embed the document with the Universal Sentence Encoder / TF-IDF

% STEP 3 
For the 3rd Step, we consider two different approaches: \acrlong{hac} and K-means. The first one (\acrshort{hac}) was used also in the previous chapter, and is very important for us because it does not require to specify the number of clusters wanted. This is ideal for situations where we do not know a-priori the number of topics or headlines that we are looking for. It is also very useful for providing insights at the different levels of the dendrogram (varying the distance threshold), to explore and identify the optimal distances and parameters by observing the intermediate clusters.
Instead, K-means is used to have higher accuracy in identifying the clusters. It works by deciding the number of output clusters in advance.
In a controlled experiment like ours, we know this parameter from the ground truth. %: the number of clusters is the number of different 

% Clustering methods:
% There are multiple clustering methods, and document representations that influence the clustering. We decided to use a method that does not require to specify the number of clusters wanted.
% We started with this specific method (also used in the previous Chapter):
% Hierarchical Agglomerative Clustering (ward method, euclidean distance), which  is very flexible in showing how the clusters evolve when the distance threshold is raised

% STEP 4
For step 4, clustering evaluation, we need to find suitable metrics that can describe how well the produced clusters correspond to the ground truth.
By looking at the literature~\citep{romano2016adjusting,warrens2022understanding}, it emerged that the most used metrics for comparing clusters are \acrfull{ari} and \acrfull{ami}.
The difference between the two is that they are based on different theories. The former is based on pair counting (counting the pairs that appear or not in the same cluster in the reference and in the evaluation), while the latter is based on Shannon Information Theory. In practice, \acrshort{ari} works better when ground truth clustering has large equal sized clusters, while \acrshort{ami} is better when there exist small clusters and ground truth clustering may be unbalanced~\citep{warrens2022understanding}.
% \todoAW{citation?}
Given the statistics of our datasets, we know that \acrshort{ari} will be better to measure the clustering at the \emph{headline} level (reference clusters are always with $size=3$), while \acrshort{ami} will be better for the clustering at the topic level (very different in size, unbalanced).
% \todoAW{I think you need to be more explicit in showing how you come to these conclusions.}



% Clustering evaluation metrics:
% Although clustering is an unsupervised task, we need to see how well the clustering matches with the ground truth annotations of the data. 
% The most used metrics for comparing clustering are:
% Adjusted Rand index,
% Adjusted Mutual Information.



% STEP 5 comparing
For the last step, comparing, we use the two metrics to understand what is the effect of removing the persuasion terms.

% \subsubsection{Results}

% This experiment has several results.

We show the results in the following three paragraphs (1: \acrshort{hac}, 2: K-means, 3: inspection of the predictions), before wrapping up with the findings and limitations. % in Subsection~\ref{ssec:lp_relationship_removing_findings}


% \subsubsection{Data}

% We need some data that contains groups of articles that are related to the same events. There are two different datasets that we can use for having the clustering ground truth:

% TODO: include in approach
% Between these two datasets (AllSides and Google Headlines), we want to be using good quality ground truth for document clustering: so that at least we start from gold-standard groups, defined by human annotators. For this reason, we prefer AllSides with respect to the Google News dataset because it is built and annotated by humans instead of being an output of a clustering algorithm already.

% Step 4 results (curve)
\subsubsection{Hierarchical Agglomerative Clustering}

With \acrshort{hac}, we have the advantage of being able to observe the gradual aggregation into larger clusters.
Therefore, in this paragraphs we observe the effects of increasing the distance threshold in hierarchical clustering.
% , we see how the metrics of \acrshort{ari} and \acrshort{ami} behave.

The value of the metrics can be computed by comparing the ground-truth clustering with the predicted one.
We are using the AllSides dataset, so we just consider the groupings of the headlines (triples) or topic labels (more large clusters) to be the ground truth.
By plotting the metric values against the increasing threshold of distance of the \acrshort{hac}, we can observe how both \acrshort{ari} and \acrshort{ami} increase until a certain point, then decreases again.

\begin{figure}[!htbp]
    \centering
    \includegraphics[width=\linewidth]{figures/sentpropnoise_4_en_tfidf_fitness_topic-cropped.pdf}
    \caption{\acrshort{ari} with increasing distance threshold on TF-IDF features.}
    \label{fig:hierarchical_sentpropnoise_evolution}
\end{figure}

Figure~\ref{fig:hierarchical_sentpropnoise_evolution} shows the values of \acrshort{ari} for a simplified case, where only $4$ headlines are considered.
On the $x$ axis, we have the Euclidean distance which corresponds to the current progress of clustering: from the left to the right, initial small clusters are merged and become bigger.
If we observe the line for \textit{complete text}, we can see that it starts on the left with increasing values, then reaches the maximum in the centre and then the score goes down again. At the beginning and at the end, the value is low because the distance threshold is either too tight (left) or too relaxed (right) and the corresponding evaluation clusters are too small (left) or too big (right).
At the center it is more similar to the ground truth, so both the \acrshort{ari} and \acrshort{ami}
%\todoAW{You haven't told me what these are yet, I don't think. Where do you explain how they are calculated?}
scores are higher.

% The interpretation of this curve is that, when the hierarchical clustering begins to raise the threshold, the clusters match more with the gold clusters, until a certain point where distinct clusters are merging together and therefore lowering the scores.
At this point we do the comparison with the other collections of articles where each one of them has been cleaned from sentiment and/or propaganda words. We see in this figure that, while sentiment does not seem to have much impact on clustering, removing propaganda increases the ability to cluster more similarly to the reference.

% We can compare the behaviour of this curve between the full text and the text without the loaded/propaganda pieces.
The comparison can be performed at the maximum point, where the threshold is optimal, % (we should truncate the clustering there)
or we can compare the full curve. For simplicity, we compare the maximum value of the curve, that in this case is $1.0$.
%reporting also the distance where it has been reached.
Nonetheless, the full curve shows the same results, as seen in the figure above (higher maximum point, higher curve).

As the figure shows, removing propaganda helps TF-IDF reaching 100\% perfect clustering with threshold 1.26 euclidean distance (12 articles on 3 topics: Supreme court, Elections, Coronavirus, Supreme Court). Instead without removal, TF-IDF misplaces some elements.


% table: step 5 results? Check
\subsubsection{K-Means}
For evaluating the effects with different sizes of datasets, we show here some results with K-Means.

% \todoAW{Don't have huge captions like this... move the description of the table into the body of the text.}
\begin{table}[!htbp]
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{r|r|r|llll|llll}
                                          &                               &                             & \multicolumn{4}{c|}{Headlines clustering}                                  & \multicolumn{4}{c}{Topic clustering}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \\ \cline{4-11}
            \multirow{-2}{*}{\#headlines} & \multirow{-2}{*}{\# articles} & \multirow{-2}{*}{\# topics} & \multicolumn{1}{l|}{Full text}                                             & \multicolumn{1}{l|}{No sentiment}                                          & \multicolumn{1}{l|}{No propaganda}                                                                           & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}No propaganda\\ and no sentiment\end{tabular}}                & \multicolumn{1}{l|}{Full text}                                             & \multicolumn{1}{l|}{No sentiment}                                                                              & \multicolumn{1}{l|}{No propaganda}                                                                            & \multicolumn{1}{l}{\begin{tabular}[c]{@{}l@{}}No propaganda\\ and no sentiment\end{tabular}}                 \\ \hline
            2                             & 6                             & 2                           & \multicolumn{1}{l|}{1.0}                                                   & \multicolumn{1}{l|}{1.0}                                                   & \multicolumn{1}{l|}{1.0}                                                                                     & 1.0                                                                                                          & \multicolumn{1}{l|}{1.0}                                                   & \multicolumn{1}{l|}{1.0}                                                                                       & \multicolumn{1}{l|}{1.0}                                                                                      & 1.0                                                                                                          \\ \hline
            4                             & 12                            & 3                           & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.390R\\ .553M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.390R\\ .553M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.645R\\ \cellcolor{green}.798M\end{tabular}} & \begin{tabular}[c]{@{}l@{}}\cellcolor{green}.645R\\ \cellcolor{green}.798M\end{tabular}                      & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.734R\\ .742M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.734R\\ .742M\end{tabular}}                                     & \cellcolor{green}1.0                                                                                          & \cellcolor{green}1.0                                                                                         \\ \hline
            10                            & 30                            & 6                           & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.616R\\ .765M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.616R\\ .765M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.634R\\ \cellcolor{green}.771M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.634R\\ \cellcolor{green}.771M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.547R\\ .724M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.547R\\ .724M\end{tabular}}                                     & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.558R\\ \cellcolor{green}.730M\end{tabular}}  & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.558R\\ \cellcolor{green}.730M\end{tabular}} \\ \hline
            100                           & 300                           & 35                          & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.461R\\ .585M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.455R\\ .584M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.461R\\ .581M\end{tabular}}                                   & \begin{tabular}[c]{@{}l@{}} \cellcolor{green}.467R\\ \cellcolor{green}.599M\end{tabular}                     & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.271R\\ .513M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}} \cellcolor{red!50}.260R\\ \cellcolor{green}.516M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}} \cellcolor{green}.274R\\ \cellcolor{green}.514M\end{tabular}} & \begin{tabular}[c]{@{}l@{}} \cellcolor{red!50}.263R\\ \cellcolor{green}.515M\end{tabular}
        \end{tabular}%
    }
    \caption{Results of clustering applied to TF-IDF features with K-means.}
    \label{tab:sentpropnoise_tfidf}
\end{table}


% analysis of results
Table~\ref{tab:sentpropnoise_tfidf} is showing how, from a small corpus to bigger corpora, the effect of removing the persuasion words is changing.
Full text is compared against \textit{no sentiment} (sentiment words have been removed), \textit{no propaganda} (propaganda words have been removed) and \textit{no sentiment and propaganda}. For each row, the values represent the \acrshort{ari} (denoted with \textit{R}) and \acrshort{ami} (denoted with \textit{M} for two different granularities: headline and topic clustering. Higher values represent predicted clusters more similar to the reference ones (improvements highlighted in green), while lower values represent more difference (deterioration shown in red). The different rows represent increasing dataset size.
The different rows represent the number of clusters considered from the AllSides dataset.

We notice that in the first row (2 \#headlines), with only two headlines, the metrics suggest that the evaluation clusters are identical to the reference clusters (score of $1.0$ both \acrshort{ari} and \acrshort{ami}).
In the second row (4 \#headlines), we can see that (as previously in Figure~\ref{fig:hierarchical_sentpropnoise_evolution}) with topic clustering we reach $1.0$ with \acrshort{ari} and \acrshort{ami}, because we manage to match perfectly with the ground truth clusters.
This happens with the removal of propaganda, while the removal of sentiment shows no effects.
With the headline clustering instead, we still have some significant improvements (from $.390R$ to $.645R$, but we cannot reach $1.0$.

In the third row (10 headlines), we still see a similar improvement caused by the removal of propaganda. In this case, the improvement is smaller, both for headline and topic clustering.

Finally, in the fourth row with the biggest subset of data made of 100 headlines, we see that the effects of removing sentiment or propaganda decrease for both tasks. For the headlines clustering, only when removing both sentiment and propaganda we see an improvement with the used metrics, and the improvement is quite small (change of around $1.3\%$ \acrshort{ari} and $2.3\%$ \acrshort{ami}). For the topic clustering, the scores change only of some percentage points, and we also see some degradation on the \acrshort{ari} metric.

% USE table 4.2
For comparison, we compute the same metrics with the same clustering method but this time with a more complex model for document embedding (\acrshort{use}). This sequence model has two main differences with respect to count-based models (e.g. TF-IDF): it accounts for the order of the words, because it is a sequence model, and it can make use of synonyms because it is based on the distributional semantics (semantic similarity based on the context)~\citep{firth1957synopsis}. Since this model accounts for the sequence of words, and since we may remove words and break the semantics of the articles when cleaning from sentiment or propaganda, we need to have this comparison.

\begin{table}[!htbp]
    \resizebox{\textwidth}{!}{%
        \begin{tabular}{r|r|r|llll|llll}
                                          &                               &                             & \multicolumn{4}{c|}{Headlines clustering}                                  & \multicolumn{4}{c}{Topic clustering}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \\ \cline{4-11}
            \multirow{-2}{*}{\#headlines} & \multirow{-2}{*}{\# articles} & \multirow{-2}{*}{\# topics} & \multicolumn{1}{l|}{Full text}                                             & \multicolumn{1}{l|}{No sentiment}                                                                             & \multicolumn{1}{l|}{No propaganda}                                                                           & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}No propaganda\\ and no sentiment\end{tabular}}                & \multicolumn{1}{l|}{Full text}                                             & \multicolumn{1}{l|}{No sentiment}                                                                              & \multicolumn{1}{l|}{No propaganda}                                                                             & \multicolumn{1}{l}{\begin{tabular}[c]{@{}l@{}}No propaganda\\ and no sentiment\end{tabular}}                 \\ \hline
            2                             & 6                             & 2                           & \multicolumn{1}{l|}{1.0}                                                   & \multicolumn{1}{l|}{1.0}                                                                                      & \multicolumn{1}{l|}{1.0}                                                                                     & 1.0                                                                                                          & \multicolumn{1}{l|}{1.0}                                                   & \multicolumn{1}{l|}{1.0}                                                                                       & \multicolumn{1}{l|}{1.0}                                                                                       & 1.0                                                                                                          \\ \hline
            4                             & 12                            & 3                           & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.287R\\ .403M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.543R\\ \cellcolor{green}.641M\end{tabular}}  & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.287R\\ .403M\end{tabular}}                                   & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.543R\\ \cellcolor{green}.641M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.566R\\ .513M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.713R\\ \cellcolor{green}.750M\end{tabular}}   & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.566R\\ .513M\end{tabular}}                                     & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.713R\\ \cellcolor{green}.750M\end{tabular}} \\ \hline
            10                            & 30                            & 6                           & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.313R\\ .416M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.408R\\ \cellcolor{green}.509M\end{tabular}}  & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.313R\\ .416M\end{tabular}}                                   & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.343R\\ \cellcolor{green}.434M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.301R\\ .479M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.331R\\ \cellcolor{green}.507M\end{tabular}}   & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.301R\\ .479M\end{tabular}}                                     & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.436R\\ \cellcolor{green}.533M\end{tabular}} \\ \hline
            100                           & 300                           & 35                          & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.250R\\ .362M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{red!50}.240R\\ \cellcolor{green}.367M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}\cellcolor{green}.251R\\ \cellcolor{green}.372M\end{tabular}} & \begin{tabular}[c]{@{}l@{}} \cellcolor{red!50}.234R\\ .362M\end{tabular}                                     & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}}.185R\\ .420M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}} \cellcolor{green}.191R\\ \cellcolor{red!50}.408M\end{tabular}} & \multicolumn{1}{l|}{\begin{tabular}[c]{@{}l@{}} \cellcolor{green}.210R\\ \cellcolor{red!50}.418M\end{tabular}} & \begin{tabular}[c]{@{}l@{}} \cellcolor{green}.223R\\ \cellcolor{red!50}.418M\end{tabular}
        \end{tabular}%
    }
    \caption{Results of the clustering applied to USE features with K-Means.}
    \label{tab:sentpropnoise_use}
\end{table}


Table~\ref{tab:sentpropnoise_use} shows the results when USE is used to compute the document representations.
The difference from Table~\ref{tab:sentpropnoise_tfidf} is that the vector representations are derived from the USE model instead of computing a TF-IDF representation of the texts.
With respect to the TF-IDF results, we can see that when we remove propaganda from the articles, we have less impact. This time, the improvement is due to the removal of the sentiment from the articles.
% when size increases
Also here, as with TF-IDF, the effects of removing persuasion decay when the dataset increases in size.

% USE meaning
The meaning of these results
%\todoAW{If you're interpreting the results, I'd create a conclusions section.}
is that with such a complex model (USE),
propaganda removal does not help to improve the clustering results, even with a small dataset.
%\todoAW{Doesn't help with what? You haven't really shown how your results answer your research questions.}
Propaganda pieces in an article are usually more than isolated words, and are spans with a longer length. Instead, adjectives (one of the common manifestations of sentiment) are frequently isolated words. USE with respect to TF-IDF is more exposed to the sequence of words, and by inspecting the results of removing persuasion from articles we can see that the sentences are incomplete and cannot stand on their own. For this reason, a simpler model like TF-IDF is being helped by the removal of propaganda, while actually for USE the sentences become broken and the clustering struggles more.

% Discrepancy between AMI and ARI
In the two tables, we see that there are some cases where the \acrshort{ari} and \acrshort{ami} metrics provide opposite direction (improvement vs degradation). In those cases, we need to keep into consideration that the two metrics come from two different theories, and also that the values described above are still relatively close to each others.
Having used a quite small number of data samples for this experiment, these two metrics are showing slight differences and not converging.
%\todoAW{I think you need a much more critical comparison of the two methods, to give some indication of exactly why the methods give the different results that they do.}
% Therefore, moving one article from one cluster to another one, may be seen as improvement or not

\subsubsection{Inspection of the predictions}

% Why? What?
In addition to the analysis of the previous paragraphs, we would like to take a closer look into the predictions, to understand better the quantitative results just described.

For simplicity, we consider the case where we have 10 headlines and we use TF-IDF (corresponding to the third row of table~\ref{tab:sentpropnoise_tfidf}). We choose the TF-IDF result because it is easier to analyse the features and see what is happening.
Let’s consider for inspection the articles belonging to two clusters (IDs given by our experimentation): cluster 0\footnote{\url{https://www.allsides.com/story/biden-leads-vote-count-trump-initiates-legal-challenges}} and cluster 7.\footnote{\url{https://www.allsides.com/story/what-watch-2020-presidential-election}}
They each include three articles, and cover the US elections of 2020. The first one was published on 5th November 2020, while the second on 3rd November 2020. So they are quite similar in the entities mentioned, but the most recent one is centred on the legal challenges initiated for the vote counts while the other headline is still pre-vote (3rd of November was the election day). This means that it is challenging for clustering to differentiate between the two ground truth clusters because a lot of terms in common exist.

\begin{table}[!htbp]
    \centering
    \begin{tabular}{c|c|c}
                           & Articles from headline 0 & Articles from headline 7 \\
        \hline
        Full article       & 0 0 7                    & 7 0 7                    \\
        Without propaganda & 0 0 7                    & 7 7 7
    \end{tabular}
    \caption{Inspection of how clustering changes when removing propaganda.}
    \label{tab:sentpropnoise_inspection}
\end{table}

% In the K-Means TF-IDF they have been labelled as:
% 1, 1, 0 and 0, 1, 0 with the full text, while 1, 1, 2 and 2, 2, 2 when removing the propaganda and sentiment. The first and last article of cluster 7 are able to be grouped to the cluster 7 instead of cluster 0.

% The ground truth for cluster 0 is here https://www.allsides.com/story/trump-mounts-legal-challenges-biden-gains-ground-vote-count and for cluster 7 here https://www.allsides.com/story/what-watch-2020-presidential-election . They are both about US elections (3 November and 5 November)

% what happened
Table~\ref{tab:sentpropnoise_inspection} shows how the articles belonging to two headlines get clustered when considered in full (first row) and when propaganda is removed (second row).
We can see that one article from headline 7 (the middle one) is clustered together with the ones from headline 0 (first row), while when propaganda is removed, it is correctly clustered together with its companions (second row).

% Term importance
Looking at the TF-IDF features for the articles, we see that when we consider the version without propaganda, terms like \emph{win} (win, winner, ..) are removed. These terms are in common between the two clusters and act as noise for the clustering.
In this way, the distinguishing terms of each headline are able to emerge and have more importance:
\emph{Lead} in cluster 0 (5th November),
\emph{Patience}, \emph{legal}, \emph{wait} in cluster 7 (3 November).

The removal of these terms helps in the fine-grained differentiation of the stories.
% but may not help with coarse topic clustering
However, when there are many different headlines to identify, these removals can also be detrimental.


\subsubsection{Findings and limitations} % and limitations
\label{ssec:lp_relationship_removing_findings}
% meaning of the results

From this whole experiment, we have the overall finding that removing persuasion from news articles helps to recognise clusters, but only in specific conditions:
\begin{enumerate}
    \item The clusters have to be not too many (less than 100).
          % \todoAW{Is that figure of 100 absolute? Looks very close to your figure of 138 articles. How did you arrive at this number?}
          % \todomargin{138 is for the Small Variations Dataset, here experimental setup is article-level and not sentence-level}
          Increasing the number of ground truth clusters reduces the effect of the removal. This happens because the removal of persuasion words causes also a removal of some topical terms. When the number of clusters considered increases, it increases also the possibility to have more similar clusters. As a consequence, the clustering is penalysed because some topical words have been removed, and the \acrshort{ari} and \acrshort{ami} measures decrease.
    \item For count-based models, the improvements are better when propaganda is removed. These terms act as noise and it is better to remove them to allow the topical words to have higher weights.
    \item For language models like USE, removing propaganda can in some cases be detrimental because the sentences lose the semantics on which these models work.
    \item The findings are analogous both for \acrshort{hac} and for K-means.
\end{enumerate}

% Slightly easier to cluster when sentiment and propaganda words are removed from the corpus.
% So propaganda and sentiment are acting like noise in clustering.

There are some limitations to this experiment. Some of them are a direct consequence of the conditions listed above:

\begin{enumerate}
    \item When increasing the size, the difference on the metrics used become smaller and smaller. This means that this approach does not scale well to thousands of headlines. This is, as explained above, a consequence of the topical words being accidentally removed when removing the persuasion words.
          % \todoAW{Is this a consequence of the curse of dimensionality? If so, it's worth being explicit about it. It's worth being explicit if it isn't, come to that...}
    \item Removing terms from articles makes them incorrect grammatically. For TF-IDF encoding, this is not a problem. Instead, for USE it becomes problem, as this language model encodes the sentence based on the sequence of words received. If the sentences do not make sense, their encoding diverges and we cannot use successfully these representations to cluster the articles together.
          %\todoAW{What exactly is the problem, and how does it affect your analysis?}
    \item Since some words belong both to persuasion and to the topic, by removing them it becomes more difficult to form the correct cluster.
          %\todoAW{As my comments have suggested, I think this is a pretty fundamental issue. Even if you don't do any more experiments, I think you probably need a unpick the issues a bit more.}
          This is why using generative models to perform non-persuasive rephrasing~\citep{bagdasaryan2022spinning} could be worth exploring in future works. However, we leave this out of scope as such a model would introduce too many variations difficult to control. %(choice of terms, but still some meaning).
          %\todo{There exists some model that rephrase propagandistic content in non-propagandistic style. What about applying them and compare?}
\end{enumerate}

In addition, we could benefit from knowing more information about the sources of the pieces of text included. This information could contextualise the articles and potentially allow us to find groups of sources that are easier to cluster together than others. This will be considered in the next Chapter~\ref{chap:political_sides}.

Or also, it could be useful adding the information about the topic of the article to find if different topics behave in different ways. The topics will be introduced in our last experimental Chapter~\ref{chap:topics}.

\section{\statusgreen Discussion}

This section contains the discussion of all the results of this chapter. We start with the findings from each of the four Research sub-Questions:

% each RQ
\begin{enumerate}[label={\textbf{RQ2.\arabic*:}},leftmargin=2cm]
    \item \emph{To what extent could we automatically detect the persuasion techniques used by writers?} Sentiment is detected through lexicons and sentiment treebanks. Propaganda, instead, is recognised with deep learning models trained on fine-grained datasets, which can also be quite unreliable (low F1 of $22.5\%$).
          %For populism we do not have detection models, but for our initial findings it seems to be weakly correlated with propaganda.
          %\todoAW{This isn't a discussion, it's a summary.}
          Answered in Section~\ref{sec:lp_techniques}. %\todomargin{this is not a finding/discussion}
    \item \emph{Which persuasion techniques are detected more frequently than others?} We observed that the most common techniques relate to loaded language (through propaganda and sentiment detection). However, the most common techniques are not the ones that differ the most. More subtle techniques, like Doubt and Appeal to fear, are the ones that emerge more when doing a comparative analysis between multiple versions of the same article.
    \item \emph{How do similar news articles differ in their use of persuasion techniques?} In some cases the words that change between multiple versions of the same detail, also cause a change in the detected persuasion. We managed to find that techniques like \texttt{Doubt}, \texttt{Appeal\_to\_fear-prejudice} and \texttt{Repetition} are the ones that are mostly affected by the variations in expressing the same detail.
          \texttt{Loaded\_anguage}, on the other side, is more ubiquitous since news sources are competing for the attention of the reader, and emerges less in a comparative analysis.
          However, in many cases, the differences between the articles cannot be described in terms of differences in detected sentiment or propaganda. This could be due to other types of variation: word choices/synonyms that are not the same word and do not apparently bring persuasion differences.
          %\todoAW{Examples?}
          Or also we have false positives in the detection (especially sentiment) that make it more difficult to see the changed persuasion. Answered in Section~\ref{ssec:lp_relationship_small_variations}.
    \item \emph{To what extent could persuasion techniques be used to identify related news articles?} By removing sentiment and/or propaganda, the clustering of related news articles improves slightly. This improvement is small but it is a sign that the non-topical layer is acting as noise/obstacle in recognising the topical layer. This is a weak verification of our hypothesis presented in Chapter~\ref{ssec:lit_layers_of_info} where we assumed that the news articles are a mix between two layers of topical and non-topical words.  We answered this question in Section~\ref{ssec:lp_relationship_removing}.
\end{enumerate}

% Findings:

% \begin{itemize}
%     \item 
% \end{itemize}

Therefore, we give here an answer to our comprehensive \acrshort{rq}2: \emph{To what extent can we automatically detect the persuasion techniques used in news articles?}

This chapter highlighted how, by integrating the automated detection of persuasion in news articles, we have on one side a clearer idea of the relationship between persuasion and the variations that different news sources produce when reporting events.
On the other side, we have also a deeper understanding of the limitations of the current status of this automated detection, and the repercussions it can have when we use these methods in other tasks.
Computational detection of persuasion means is quite a recent research area, and with time and more resources (datasets and models) it could clearly improve.%\todoAW{Big assumption. I'd rephrase.}

% Our findings from this chapter include:
% \begin{enumerate}
%     \item The relationship between the changed terms and propaganda language is not very straightforward: different parts do not always contain loaded language or propaganda. A lot of changes are not meaningful in terms of propaganda: multiple wording can be unrelated to persuasion. % linguistic variance.\todoAW{Not sure what you're getting at here.}
%     \item Some techniques, such as \texttt{Doubt} and \texttt{Appeal\_to\_fear-prejudice}, appear less in general but are the ones that differentiate more one version from the other. \texttt{Loaded\_language}, on the other side, is more ubiquitous since news sources are competing for the attention of the reader, and emerges less in a comparative analysis.
%     \item As we hypothesised, the persuasion in the articles is adding terms and concepts that create variations (fitting different persuasion goals). As a consequence, these selected words make it slightly more difficult to recognise groups of articles related to the same event.
%     Removing propaganda and/or sentiment from articles makes related articles slightly easier to group correctly in the case where the ground truth of the group is known.%\todoAW{Not sure what you mean by this. In most cases of cluster analysis, there's no meaningful concept of a "correct cluster"}
%     %\todoHA{For what? Not discussed earlier}
% \end{enumerate}
% \todo{check if duplicates of replies to RQs}

\section{\statusgreen Next}
% link to next chapter
In this chapter we investigated the persuasion techniques and how they relate to wording changes in similar sentences and articles.
However, we have not studied the relationship between this observed persuasion in the text and the ideals/agenda/perspective of the author/outlet.
It would be really useful to understand the context around the source of an article in order to interpret its persuasion.
For this reason, the next chapter will consider perspectives and political sides.
In this way we will try to understand if the persuasion of each political side is similar or which are the differences.
Can we observe the different goals that generated the articles (the perspective or political side) also on the persuasion itself? We will investigate what is the relationship between political sides and persuasion.
% If a different goal for the persuasion also can be observed on the persuasion itself.